{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cef8255da77ad378",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Codio Exercise 8.2: Using `PolynomialFeatures`\n",
    "\n",
    "**Estimated time: 60 minutes**\n",
    "\n",
    "**Total Points: 20 Points**\n",
    "\n",
    "\n",
    "This activity focuses on using the scikitlearn transformer `PolynomialFeatures`.  As seen in video 8.4, you can use this transformer to create the modified DataFrame with appropriate column names using the `.get_feature_names_out()` method on the fit transformer.  You will focus on building second, third, and fourth degree polynomial models using `PolynomialFeatures`, and converting the results to pandas DataFrames.\n",
    "\n",
    "## Index:\n",
    "\n",
    " - [Problem 1](#Problem-1)\n",
    " - [Problem 2](#Problem-2)\n",
    " - [Problem 3](#Problem-3)\n",
    " - [Problem 4](#Problem-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4daeaff5780c149a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Again, the automobile dataset is used.  You will build the additional features using the `horsepower` column of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('data/auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b68a9367135ea82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 1\n",
    "\n",
    "### Creating Quadratic Features\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Using the `horsepower` column, instantiate, fit, and transform a `PolynomialFeatures` transformer.  Instantiate the transformer and use the `degree` argument to create second degree polynomial features.  Assign your transformer to the variable `pfeatures`, and the transformed features as a numpy array to `quad_features` below.  Note that the `PolynomialFeatures` transformer expects a 2-dimensional input; one way to accomplish this is to use two sets of brackets to select a single column -- `auto[[colname]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7876f7339eeaf11",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "pfeatures = ''\n",
    "quad_features = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pfeatures = PolynomialFeatures()\n",
    "quad_features = pfeatures.fit_transform(auto[['horsepower']])\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(type(quad_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c9f45b50e7229ff6",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "pfeatures_ = PolynomialFeatures()\n",
    "quad_features_ = pfeatures_.fit_transform(auto[['horsepower']])\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(quad_features, quad_features_, err_msg=f'Arrays are not equal, expected {quad_features_}')\n",
    "assert type(pfeatures) == type(pfeatures_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f2a8a484b49a4ae4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 2\n",
    "\n",
    "### Creating the DataFrame\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Using the transformed array, create a DataFrame of the transformed data.  As in the lectures, use the `get_feature_names_out()` method of your fit transformer `pfeatures` from above.  Drop the bias term from the DataFrame so that you only have the columns `horsepower` and `horsepower^2`.  Assign your response as a DataFrame to the variable `poly_features_df` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65b5a0fa623f1373",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "poly_features_df = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pfeatures = PolynomialFeatures()\n",
    "quad_features = pfeatures.fit_transform(auto[['horsepower']])\n",
    "poly_features_df = pd.DataFrame(quad_features, columns=pfeatures.get_feature_names_out()).iloc[:, 1:]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(poly_features_df.shape)\n",
    "poly_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dd867950a5059c68",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "pfeatures_ = PolynomialFeatures()\n",
    "quad_features_ = pfeatures_.fit_transform(auto[['horsepower']])\n",
    "poly_features_df_ = pd.DataFrame(quad_features_, columns=pfeatures_.get_feature_names_out()).iloc[:, 1:]\n",
    "#\n",
    "#\n",
    "#\n",
    "assert poly_features_df.shape == poly_features_df_.shape\n",
    "pd.testing.assert_frame_equal(poly_features_df, poly_features_df_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65ec89ca45eee9e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 3\n",
    "\n",
    "### DataFrame with Cubic Features\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, use a transformer to create a DataFrame with features for a third degree or cubic polynomial model.  Do this by setting the `degree=3` in your transformer.  As before, drop the bias term so that your final DataFrame has the shape `(392, 3)` and has feature names `horsepower`, `horsepower^2`, and `horsepower^3`.  Assign your results as a DataFrame to `cubic_features_df` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea5b3099f652d9c4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "cubic_features_df = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pfeatures = PolynomialFeatures(degree = 3)\n",
    "cubic_features = pfeatures.fit_transform(auto[['horsepower']])\n",
    "cubic_features_df = pd.DataFrame(cubic_features, columns=pfeatures.get_feature_names_out()).iloc[:, 1:]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(cubic_features_df.shape)\n",
    "cubic_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a0d3ba89bb693aee",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "pfeatures_ = PolynomialFeatures(degree = 3)\n",
    "cubic_features_ = pfeatures_.fit_transform(auto[['horsepower']])\n",
    "cubic_features_df_ = pd.DataFrame(cubic_features_, columns=pfeatures_.get_feature_names_out()).iloc[:, 1:]\n",
    "#\n",
    "#\n",
    "#\n",
    "assert cubic_features_df.shape == cubic_features_df_.shape\n",
    "pd.testing.assert_frame_equal(cubic_features_df, cubic_features_df_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b4761c92049bf73",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "## Problem 4\n",
    "\n",
    "### Experimenting with Multiple Features\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, experiment with building polynomial features for multiple columns.  Specifically, use a transformer to create a DataFrame of quadratic features (`degree = 2`) for the columns `horsepower` and `weight`.  Drop the bias term as before and examine the column names.  Note the existence of a new column `horsepower weight`.  Assign your transformed data as a DataFrame to `two_feature_poly_df` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e77b6a15eb3bf2c5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "cubic_features_df = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "pfeatures = PolynomialFeatures(degree = 2)\n",
    "two_features = pfeatures.fit_transform(auto[['horsepower', 'weight']])\n",
    "two_feature_poly_df = pd.DataFrame(two_features, columns=pfeatures.get_feature_names_out()).iloc[:, 1:]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(two_feature_poly_df.shape)\n",
    "two_feature_poly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3be9268a420ca07b",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "pfeatures_ = PolynomialFeatures(degree = 2)\n",
    "two_features_ = pfeatures_.fit_transform(auto[['horsepower', 'weight']])\n",
    "two_feature_poly_df_ = pd.DataFrame(two_features_, columns=pfeatures_.get_feature_names_out()).iloc[:, 1:]\n",
    "#\n",
    "#\n",
    "#\n",
    "assert two_feature_poly_df.shape == two_feature_poly_df_.shape\n",
    "assert set(list(two_feature_poly_df.columns)) == set(list(two_feature_poly_df_.columns))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2fd941447cd10a97",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Summary\n",
    "\n",
    "Now that you have the hang of using `PolynomialFeatures`, you will combine the transformer with an estimator using scikitlearn's pipeline utilities.  As demonstrated in the videos, the pipeline is a handy abstraction for combining the data transformations with the model in a single object.  This is especially handy when making predictions with new data points."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
