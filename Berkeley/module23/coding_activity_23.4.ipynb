{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1af27d3e65f74335",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 23.4: Fine Tuning a Pre-trained Network\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 30**\n",
    "\n",
    "In addition to the use of a pre-trained network to extract features from a different dataset, the weights can be adjusted or **fine-tuned** as a last step to squeeze additional performance from the network.  To do so, you will again use the `EfficientNetV2B0` network on the `cifar10` data from `keras`.  This time you are encouraged to use the functional API syntax to construct your network.  \n",
    "\n",
    "For a second example, consult the `keras` documentation example [here](https://keras.io/guides/transfer_learning/). \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 20:50:38.514197: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-03 20:50:38.514237: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "sub_indices = pd.DataFrame(y_train, columns= [\"labels\"]).groupby('labels', group_keys=False).apply(lambda x: x.sample(frac=0.3, random_state=123)).index\n",
    "X_train = X_train[sub_indices]\n",
    "y_train = y_train[sub_indices]\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8d37aca8ee95d87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Training the Network to Convergence\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `EfficientNetV2B0` as `base_model` with appropriate input shape and the functional API to create a model using the `base_model`, flatten the results, pass through a `Dense` layer of 100 units and an appropriate output layer.  Name the `Input` inputs and the output layer `outputs`.  Compile the model and fit it using 20 epochs, assigning the history as `history`.  \n",
    "\n",
    "**Make sure the `base_model` weights are not trainable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e92e20d0c85d3026",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 20:50:44.170421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-03 20:50:44.170485: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-03 20:50:44.170512: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (victorbravo-kineticenjoy): /proc/driver/nvidia/version does not exist\n",
      "2022-08-03 20:50:44.171293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 27s 46ms/step - loss: 1.5263 - accuracy: 0.4678 - val_loss: 1.2593 - val_accuracy: 0.5526\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 1.2546 - accuracy: 0.5595 - val_loss: 1.2279 - val_accuracy: 0.5658\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 1.1702 - accuracy: 0.5860 - val_loss: 1.1818 - val_accuracy: 0.5811\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 1.1284 - accuracy: 0.6021 - val_loss: 1.1708 - val_accuracy: 0.5882\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 1.0954 - accuracy: 0.6141 - val_loss: 1.1403 - val_accuracy: 0.6022\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 1.0686 - accuracy: 0.6255 - val_loss: 1.1432 - val_accuracy: 0.6023\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 1.0455 - accuracy: 0.6331 - val_loss: 1.2466 - val_accuracy: 0.5797\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 1.0225 - accuracy: 0.6337 - val_loss: 1.1220 - val_accuracy: 0.6106\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.9936 - accuracy: 0.6482 - val_loss: 1.1637 - val_accuracy: 0.5964\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.9720 - accuracy: 0.6566 - val_loss: 1.1887 - val_accuracy: 0.5917\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.9671 - accuracy: 0.6596 - val_loss: 1.1491 - val_accuracy: 0.6070\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.9500 - accuracy: 0.6688 - val_loss: 1.1656 - val_accuracy: 0.5965\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.9317 - accuracy: 0.6705 - val_loss: 1.1246 - val_accuracy: 0.6099\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.9071 - accuracy: 0.6773 - val_loss: 1.1438 - val_accuracy: 0.6073\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.8927 - accuracy: 0.6847 - val_loss: 1.1829 - val_accuracy: 0.6020\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.8737 - accuracy: 0.6911 - val_loss: 1.1786 - val_accuracy: 0.6018\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.8666 - accuracy: 0.6975 - val_loss: 1.1438 - val_accuracy: 0.6106\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 0.8481 - accuracy: 0.6999 - val_loss: 1.1665 - val_accuracy: 0.6084\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.8321 - accuracy: 0.7096 - val_loss: 1.1938 - val_accuracy: 0.6051\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.8144 - accuracy: 0.7123 - val_loss: 1.2177 - val_accuracy: 0.6071\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1, 1, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               128100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,048,422\n",
      "Trainable params: 129,110\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "base_model = ''\n",
    "inputs = ''\n",
    "x = ''\n",
    "x = ''\n",
    "x = ''\n",
    "output = ''\n",
    "model = ''\n",
    "#be sure to compile\n",
    "\n",
    "bottom_model = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "base_model = EfficientNetV2B0(input_shape = (32, 32, 3), include_top=False)\n",
    "inputs = Input(shape = (32, 32, 3))\n",
    "x = base_model(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation = 'relu')(x)\n",
    "output = Dense(10, activation = 'sigmoid')(x)\n",
    "base_model.trainable = False\n",
    "model = Model(inputs, output)\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "bottom_model = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "                    epochs = 20)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c7a974852163092b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 31s 49ms/step - loss: 1.5299 - accuracy: 0.4687 - val_loss: 1.3571 - val_accuracy: 0.5157\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 1.2544 - accuracy: 0.5585 - val_loss: 1.2741 - val_accuracy: 0.5442\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 1.1771 - accuracy: 0.5859 - val_loss: 1.1896 - val_accuracy: 0.5814\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 1.1329 - accuracy: 0.5981 - val_loss: 1.1526 - val_accuracy: 0.5956\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 1.0908 - accuracy: 0.6169 - val_loss: 1.1891 - val_accuracy: 0.5824\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 1.0667 - accuracy: 0.6225 - val_loss: 1.1429 - val_accuracy: 0.6024\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 1.0369 - accuracy: 0.6365 - val_loss: 1.1852 - val_accuracy: 0.5889\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 1.0202 - accuracy: 0.6380 - val_loss: 1.1331 - val_accuracy: 0.6022\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.9965 - accuracy: 0.6492 - val_loss: 1.1569 - val_accuracy: 0.5972\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.9817 - accuracy: 0.6552 - val_loss: 1.1438 - val_accuracy: 0.6068\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.9676 - accuracy: 0.6622 - val_loss: 1.1455 - val_accuracy: 0.6059\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.9458 - accuracy: 0.6645 - val_loss: 1.1353 - val_accuracy: 0.6077\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.9251 - accuracy: 0.6698 - val_loss: 1.1258 - val_accuracy: 0.6138\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.9120 - accuracy: 0.6764 - val_loss: 1.1635 - val_accuracy: 0.6049\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.8969 - accuracy: 0.6828 - val_loss: 1.1164 - val_accuracy: 0.6159\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.8815 - accuracy: 0.6888 - val_loss: 1.1404 - val_accuracy: 0.6122\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.8728 - accuracy: 0.6921 - val_loss: 1.1695 - val_accuracy: 0.6080\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.8524 - accuracy: 0.7005 - val_loss: 1.1612 - val_accuracy: 0.6059\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.8433 - accuracy: 0.7009 - val_loss: 1.1765 - val_accuracy: 0.6076\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.8268 - accuracy: 0.7073 - val_loss: 1.1697 - val_accuracy: 0.6135\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "base_model_ = EfficientNetV2B0(input_shape = (32, 32, 3), include_top=False)\n",
    "inputs_ = Input(shape = (32, 32, 3))\n",
    "x_ = base_model(inputs_)\n",
    "x_ = Flatten()(x_)\n",
    "x_ = Dense(100, activation = 'relu')(x_)\n",
    "output_ = Dense(10, activation = 'sigmoid')(x_)\n",
    "model_ = Model(inputs_, output_)\n",
    "model_.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "bottom_model_ = model_.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "                    epochs = 20)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(base_model) == type(base_model_)\n",
    "assert type(bottom_model) == type(bottom_model_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-72d9644d3c68011b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Setting to Trainable\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "After fitting the model above, you can set the layers to trainable to update the weights.  Below, set the final five layers to trainable in the `base_model` as demonstrated in the lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable #are the base model weights set to trainable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17e4f0a4de6dc3b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "base_model.trainable = True\n",
    "for layer in '':\n",
    "    #make trainable\n",
    "    pass\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "for i, layer in enumerate(base_model.layers[-10:]):\n",
    "    print(f'Layer is trainable: {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-279935493600bece",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "base_model_.trainable = True\n",
    "for layer in base_model_.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "#\n",
    "#\n",
    "#\n",
    "for i, layer in enumerate(base_model.layers[-5:]):\n",
    "    assert layer.trainable == True\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0307a936396eedc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Refitting the network\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Finally, specify the `model` compilation and fit this again for 10 epochs, assigning the resulting history to `fine_tuned_history` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-75f43fbafe9c0840",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 39s 57ms/step - loss: 3.2024 - accuracy: 0.4689 - val_loss: 1.5707 - val_accuracy: 0.5584\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 1.1948 - accuracy: 0.6214 - val_loss: 1.3980 - val_accuracy: 0.5848\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.9943 - accuracy: 0.6783 - val_loss: 1.3801 - val_accuracy: 0.6092\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.9086 - accuracy: 0.7088 - val_loss: 1.4395 - val_accuracy: 0.6109\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.8263 - accuracy: 0.7309 - val_loss: 1.4466 - val_accuracy: 0.6098\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.7448 - accuracy: 0.7548 - val_loss: 1.4951 - val_accuracy: 0.6130\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 0.7017 - accuracy: 0.7729 - val_loss: 1.5713 - val_accuracy: 0.6138\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 0.6476 - accuracy: 0.7979 - val_loss: 1.6686 - val_accuracy: 0.6142\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.6045 - accuracy: 0.8041 - val_loss: 1.6253 - val_accuracy: 0.6155\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.5829 - accuracy: 0.8157 - val_loss: 1.7565 - val_accuracy: 0.6148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.815666675567627"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "fine_tuned_history = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "fine_tuned_history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 10)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "fine_tuned_history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c60ddea5358927c2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 31s 52ms/step - loss: 1.0456 - accuracy: 0.6992 - val_loss: 1.6868 - val_accuracy: 0.6022\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.7396 - accuracy: 0.7624 - val_loss: 1.7184 - val_accuracy: 0.6112\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.6652 - accuracy: 0.7913 - val_loss: 1.7860 - val_accuracy: 0.6119\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.6102 - accuracy: 0.8068 - val_loss: 1.7839 - val_accuracy: 0.6114\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.5670 - accuracy: 0.8263 - val_loss: 1.8409 - val_accuracy: 0.6156\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.5412 - accuracy: 0.8346 - val_loss: 1.9607 - val_accuracy: 0.6187\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.5019 - accuracy: 0.8468 - val_loss: 1.9545 - val_accuracy: 0.6193\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 0.4970 - accuracy: 0.8545 - val_loss: 1.9832 - val_accuracy: 0.6167\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.4644 - accuracy: 0.8640 - val_loss: 2.0374 - val_accuracy: 0.6152\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.4434 - accuracy: 0.8647 - val_loss: 2.0547 - val_accuracy: 0.6192\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "model_.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "fine_tuned_history_ = model_.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 10)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert len(fine_tuned_history.history['accuracy']) == len(fine_tuned_history_.history['accuracy'])\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
