{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8lBFNC7Zq4uz",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f0871d27cefa6e024f0f274470687a9",
     "grade": false,
     "grade_id": "cell-b932fb3113b39867",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 15.7: Gradient Descent with Two Features\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 40**\n",
    "\n",
    "This activity focuses on using gradient descent with two features to find the optimal parameters for a regression model.  You will use the formulas for the gradients given in the lecture together with a small synthetic dataset to explore building a regression model with two variables.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3V9lq7d0rGS6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sympy as sy\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a78dbcfc4a2679624f33ffd8ae1ac7d",
     "grade": false,
     "grade_id": "cell-4b669aae15856864",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Below, a simple dataset is created around the line $y = 4.1x + 12.5 + \\epsilon$ where $\\epsilon$ are randomly generated values drawn from a normal distribution $N(0, 2)$.  This means we want our model to uncover something close to $\\theta_0 = 12.5$ and $\\theta_1 = 4.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M01y7YoGru-s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fef8894d730>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = np.linspace(0, 5, 100)\n",
    "y = 12.5 + 4.1*x + np.random.normal(size = 100, scale = 2)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab803aaeb58e7556a585286f105355cc",
     "grade": false,
     "grade_id": "cell-b6782a11323e9040",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Adding a Bias Term\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Your two variable model will use a column of ones to stand in as the multiplier of $\\theta_0$.  Create a DataFrame with columns `['bias', 'x']` that contains a column of ones and the data `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85840811925fc78aeae5470d280895e5",
     "grade": false,
     "grade_id": "cell-dafb50ab2f85f477",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.202020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias         x\n",
       "0   1.0  0.000000\n",
       "1   1.0  0.050505\n",
       "2   1.0  0.101010\n",
       "3   1.0  0.151515\n",
       "4   1.0  0.202020"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "X = ''\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "X = pd.DataFrame({'bias':1.0, 'x':x})\n",
    "\n",
    "# Answer check\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   bias    100 non-null    float64\n",
      " 1   x       100 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba8a3bfe92241bc822139ebc160c8dd1",
     "grade": true,
     "grade_id": "cell-6dbc25e9c2e5ae80",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ff831397ea21e753a9e437993679a76",
     "grade": false,
     "grade_id": "cell-a3b21c26fca83102",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Gradient of MSE\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Complete the function `mse_grad` below.  This function will take in a (2, ) array of initial guesses for $[\\theta_0, \\theta_1]$.  Recall the formula for the partial derivative of the loss function with respect to $\\theta_0$ as:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_0} l(\\overrightarrow{\\theta}, \\overrightarrow{x}, y_i) = 2(y_i - \\theta_0x_0 - \\theta_1x_1)(-x_0)$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta_1} l(\\overrightarrow{\\theta}, \\overrightarrow{x}, y_i) = 2(y_i - \\theta_0x_0 - \\theta_1x_1)(-x_1)$$\n",
    "\n",
    "You function will return the array\n",
    "\n",
    "$$[\\frac{\\partial l}{\\partial \\theta_0}, \\frac{\\partial l}{\\partial \\theta_1}]$$\n",
    "\n",
    "Remember to find the mean of the gradient array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa0b66e9b46c37bd5396ccc41fccda80",
     "grade": false,
     "grade_id": "cell-b77154523852536f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -45.08461393, -130.37451799])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "def mse_grad(theta, x, y):\n",
    "    x0 = x.iloc[:,0]\n",
    "    x1 = x.iloc[:,1]\n",
    "    dtheta0 = np.mean(-2 * (y - theta[0] * x0 - theta[1] * x1) * x0)\n",
    "    dtheta1 = np.mean(-2 * (y - theta[0] * x0 - theta[1] * x1) * x1)\n",
    "    return np.array([dtheta0, dtheta1])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# Answer check\n",
    "mse_grad(np.array([0, 0]), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdd7e5a6d3ab11e175ed93f7671efda2",
     "grade": true,
     "grade_id": "cell-5bdd83577cd7234a",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15a48ef339854d7d166353bbfaf3831b",
     "grade": false,
     "grade_id": "cell-b4f29c3801f19335",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Use the initial value for `theta` and a learning rate of `lr = 0.01` to perform 1000 iterations of gradient descent.  Keep track of the updated array of theta as `thetas` below.  Recall the gradient descent formula as:\n",
    "\n",
    "$$\\theta_{i + 1} = \\theta_{i} - lr*grad(mse(\\theta_{i}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = [0,0]\n",
    "type(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "182a4bc366fd9a74601ac48d2f981180",
     "grade": false,
     "grade_id": "cell-b6083479fed0a1ab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([12.05895177,  4.1844691 ]),\n",
       " array([12.05939542,  4.1843329 ]),\n",
       " array([12.059837  ,  4.18419733])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "thetas = []\n",
    "theta = ''\n",
    "lr = 0.01\n",
    "for i in range(1000):\n",
    "    #track theta\n",
    "    \n",
    "    #update theta\n",
    "    pass\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "thetas = []\n",
    "theta = np.array([0, 0])\n",
    "lr = 0.01\n",
    "for i in range(1000):\n",
    "    #track theta\n",
    "    thetas.append(theta)\n",
    "    #update theta\n",
    "    current_theta = mse_grad(theta, X, y)\n",
    "    theta = theta - lr * current_theta\n",
    "\n",
    "\n",
    "# Answer check\n",
    "thetas[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7103c867390e32b4431500d48af6e09",
     "grade": true,
     "grade_id": "cell-c62f604772219e66",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 1.30374518, ..., 4.1844691 , 4.1843329 ,\n",
       "       4.18419733])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(thetas)[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5140dd9bb78f0ad1e14c79e1d2c72a14",
     "grade": false,
     "grade_id": "cell-c90318f523fd9430",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### DataFrame of updates\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, create a DataFrame that holds your theta updates from the list `thetas` as `thetas_df` below.  Name the columns `intercept`, `slope`.  Did these values converge as desired?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37c4ed4d3fff5c265281fff31b28ba90",
     "grade": false,
     "grade_id": "cell-10ecc5283b1c2461",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>12.059837</td>\n",
       "      <td>4.184197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      intercept     slope\n",
       "1000  12.059837  4.184197"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "thetas_df = ''\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "thetas_df = pd.DataFrame({'intercept':np.array(thetas)[:,0], 'slope':np.array(thetas)[:,1]})\n",
    "\n",
    "# Answer check\n",
    "thetas_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d346accda6373f9ab7f6ddaa38792414",
     "grade": true,
     "grade_id": "cell-1e88d85e535a49fb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dab337a9da1c5b43b4dd94b3e3592d6",
     "grade": false,
     "grade_id": "cell-ddd9c146b380fba1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Comparing with `sklearn`\n",
    "\n",
    "Below, a regression model from sklearn is fit and the coefficients are shown.  These should be very close to what your gradient descent routine found.  To get closer feel free to experiment with the learning rate and number of iterations.  Beware that too many iterations and too small a learning rate will be very slow to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.15437429,  4.15517307])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "coding_assignment_15.7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
