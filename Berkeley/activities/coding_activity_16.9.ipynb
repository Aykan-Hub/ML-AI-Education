{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a993931988152322b1ef541c3589863",
     "grade": false,
     "grade_id": "cell-c494d2f790e35eb6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 16.9: Investigating your own data\n",
    "\n",
    "For this activity, you are asked to go out and choose a dataset to build a classification model with.  Specifically, you are to compare the `LogisticRegression`, `KNearestNeighborsClassifier`, and `SVC` estimators in terms of performance and speed in model fitting.  You should optimize this model according to what metric you believe is the appropriate one for the task between `precision`, `recall`, or `accuracy`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8cf8899e95023a04c994264e8f9bb46",
     "grade": false,
     "grade_id": "cell-e37ce95bafcde96d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Gathering the data\n",
    "\n",
    "For your dataset, consider using an example dataset from either [kaggle](https://www.kaggle.com/) or the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).  Select an appropriate dataset that is a classification problem.  Download the data file and work in a notebook locally to perform your analysis.  Be sure to grid search different model parameters and compare the different estimators.  Construct a DataFrame of the model results with the following information:\n",
    "\n",
    "| model | train score | test score | average fit time |\n",
    "| ----- | -----   | -------   | ------- |\n",
    "| KNN | ? | ? | ? |\n",
    "| Logistic Regression | ? | ? | ? |\n",
    "| SVC | ? | ? | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "528372f60c56f0860e6e0932b0d7dc7d",
     "grade": false,
     "grade_id": "cell-f3c8278622a110d5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The assignment will expect a DataFrame with this exact structure and index and column names.  You will be graded based on the exact match of the structure of the DataFrame.  One suggestion is to build a DataFrame and write this out to `.json`, copy and past this below to create the DataFrame.  Alternatively, you can write it out to a `.csv` file and copy the text, or simply hardcode the DataFrame based on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9abac97cf0d038ce16c6b927e03be1e",
     "grade": false,
     "grade_id": "cell-9570e9b0d9b3b3a2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 1\n",
    "\n",
    "#### DataFrame of modeling results\n",
    "\n",
    "Assign your constructed results DataFrame to `results_df` below.  Be sure that the `model` column above is the index of the DataFrame, and the three column names match the order and formatting of the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(\"figure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last</th>\n",
       "      <th>times</th>\n",
       "      <th>unit</th>\n",
       "      <th>since</th>\n",
       "      <th>donated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last  times   unit  since  donated\n",
       "0       2     50  12500     98        1\n",
       "1       0     13   3250     28        1\n",
       "2       1     16   4000     35        1\n",
       "3       2     20   5000     45        1\n",
       "4       1     24   6000     77        0\n",
       "..    ...    ...    ...    ...      ...\n",
       "743    23      2    500     38        0\n",
       "744    21      2    500     52        0\n",
       "745    23      3    750     62        0\n",
       "746    39      1    250     39        0\n",
       "747    72      1    250     72        0\n",
       "\n",
       "[748 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blood = pd.read_csv('data/transfusion.data')\n",
    "blood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   last     748 non-null    int64\n",
      " 1   times    748 non-null    int64\n",
      " 2   unit     748 non-null    int64\n",
      " 3   since    748 non-null    int64\n",
      " 4   donated  748 non-null    int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 29.3 KB\n"
     ]
    }
   ],
   "source": [
    "blood.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'last'}>,\n",
       "        <AxesSubplot:title={'center':'times'}>],\n",
       "       [<AxesSubplot:title={'center':'unit'}>,\n",
       "        <AxesSubplot:title={'center':'since'}>],\n",
       "       [<AxesSubplot:title={'center':'donated'}>, <AxesSubplot:>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histograms\n",
    "blood.hist(figsize = (10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762032\n",
       "1    0.237968\n",
       "Name: donated, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blood.donated.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features from target and split training and test datasets\n",
    "X, y = blood.drop(['unit', 'since', 'donated'], axis = 1), blood.donated\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 93, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there is no aplhanumeric columns, we can just scale and classify data, no transformation needed\n",
    "# n_neighbors=5 by default!\n",
    "lgr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set scorer\n",
    "scorer = 'recall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 ms, sys: 2.23 ms, total: 50.7 ms\n",
      "Wall time: 48.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'penalty': ['l1', 'l2'], 'solver':['liblinear']}\n",
    "lgr_grid = GridSearchCV(lgr, cv = 5, param_grid = params, scoring=scorer).fit(X_train, y_train)\n",
    "lgr_train = lgr_grid.score(X_train, y_train)\n",
    "lgr_test = lgr_grid.score(X_test, y_test)\n",
    "lgr_time = np.mean(lgr_grid.cv_results_['mean_fit_time']) #+ np.mean(lgr_grid.cv_results_['mean_score_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00201077, 0.00190063]),\n",
       " 'std_fit_time': array([0.00032578, 0.00025343]),\n",
       " 'mean_score_time': array([0.00168891, 0.00162139]),\n",
       " 'std_score_time': array([9.36197115e-05, 2.63033508e-05]),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2'],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'liblinear'],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'penalty': 'l2', 'solver': 'liblinear'}],\n",
       " 'split0_test_score': array([0.03703704, 0.03703704]),\n",
       " 'split1_test_score': array([0.07407407, 0.07407407]),\n",
       " 'split2_test_score': array([0.11111111, 0.11111111]),\n",
       " 'split3_test_score': array([0.11538462, 0.11538462]),\n",
       " 'split4_test_score': array([0.07692308, 0.07692308]),\n",
       " 'mean_test_score': array([0.08290598, 0.08290598]),\n",
       " 'std_test_score': array([0.0285242, 0.0285242]),\n",
       " 'rank_test_score': array([1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 11.6 ms, total: 4.63 s\n",
      "Wall time: 4.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'n_neighbors': range(1, len(y_test), 2), 'weights':['uniform', 'distance']}\n",
    "knn_grid = GridSearchCV(knn, cv = 5, param_grid = params, scoring=scorer).fit(X_train, y_train)\n",
    "knn_train = knn_grid.score(X_train, y_train)\n",
    "knn_test = knn_grid.score(X_test, y_test)\n",
    "knn_time = np.mean(knn_grid.cv_results_['mean_fit_time']) #+ np.mean(knn_grid.cv_results_['mean_score_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00170665, 0.00153933, 0.00130014, 0.00124292, 0.00127406,\n",
       "        0.00119557, 0.00119548, 0.0011744 , 0.00114493, 0.00111589,\n",
       "        0.00121341, 0.00112524, 0.00111122, 0.00137353, 0.00116558,\n",
       "        0.00115714, 0.00117383, 0.00120444, 0.00118651, 0.00112796,\n",
       "        0.00111952, 0.00111322, 0.00112357, 0.00114851, 0.00119452,\n",
       "        0.00109944, 0.00109906, 0.00115619, 0.00116925, 0.00111866,\n",
       "        0.00113025, 0.00109477, 0.00114994, 0.00111713, 0.00110545,\n",
       "        0.00118508, 0.00121717, 0.00109539, 0.00112338, 0.00112801,\n",
       "        0.0010921 , 0.0012042 , 0.00109406, 0.00111427, 0.00109949,\n",
       "        0.0013422 , 0.00112185, 0.00122232, 0.00110679, 0.00112333,\n",
       "        0.00112181, 0.00109916, 0.00110717, 0.00115499, 0.00149474,\n",
       "        0.00116124, 0.00115328, 0.00119576, 0.00141387, 0.00114121,\n",
       "        0.00113139, 0.00112791, 0.00110955, 0.00110097, 0.00116458,\n",
       "        0.00110836, 0.00108447, 0.00108013, 0.00106111, 0.00114031,\n",
       "        0.00107021, 0.00104766, 0.0010797 , 0.00107622, 0.0010848 ,\n",
       "        0.00108142, 0.0011066 , 0.00110312, 0.00110903, 0.00111327,\n",
       "        0.00108871, 0.00105557, 0.00111485, 0.001158  , 0.0010745 ,\n",
       "        0.00110259, 0.00118175, 0.00106664, 0.00111718, 0.00107431,\n",
       "        0.00106859, 0.00105515, 0.00106874, 0.0011302 , 0.00108781,\n",
       "        0.00111537, 0.00115361, 0.00113792, 0.00104036, 0.00112181,\n",
       "        0.00128961, 0.00123687, 0.00113101, 0.00113339, 0.00116143,\n",
       "        0.00119643, 0.0011704 , 0.00112119, 0.0011755 , 0.00131321,\n",
       "        0.00105128, 0.00111613, 0.001124  , 0.00114665, 0.00111327,\n",
       "        0.0010613 , 0.00108976, 0.00106378, 0.00105982, 0.00115409,\n",
       "        0.00110288, 0.00106597, 0.00108323, 0.001052  , 0.00113659,\n",
       "        0.00107021, 0.00106964, 0.00105405, 0.00108895, 0.00104098,\n",
       "        0.0011343 , 0.00105071, 0.00120964, 0.00113082, 0.00110211,\n",
       "        0.00124578, 0.00117235, 0.00112958, 0.00108376, 0.00116615,\n",
       "        0.00117583, 0.0011167 , 0.00109925, 0.00109224, 0.00110703,\n",
       "        0.00116081, 0.00120511, 0.00111232, 0.00110416, 0.00111232,\n",
       "        0.00110474, 0.00108857, 0.0011035 , 0.00107622, 0.00114512,\n",
       "        0.00115571, 0.00107875, 0.00121665, 0.00116796, 0.0011167 ,\n",
       "        0.00106201, 0.0010921 , 0.00104537, 0.00104818, 0.00108151,\n",
       "        0.00116391, 0.00106001, 0.00108266, 0.00106268, 0.00127902,\n",
       "        0.00146852, 0.00112104, 0.0011179 , 0.00111461, 0.00106878,\n",
       "        0.00145235, 0.00173855, 0.00117459, 0.00116696, 0.00118003,\n",
       "        0.00108123, 0.00114889, 0.00125484, 0.00123978, 0.00127587,\n",
       "        0.00127206]),\n",
       " 'std_fit_time': array([1.68666099e-04, 9.13850172e-05, 7.20155780e-05, 4.53722521e-06,\n",
       "        7.02720147e-05, 1.15534406e-05, 1.50799704e-05, 2.63110431e-05,\n",
       "        4.45121804e-06, 6.55646758e-06, 1.01214974e-04, 2.47011774e-05,\n",
       "        4.84265639e-06, 2.04994230e-04, 3.44314732e-06, 1.92092593e-05,\n",
       "        4.53179974e-05, 6.44244589e-05, 1.19828201e-04, 2.85182906e-05,\n",
       "        1.69974891e-05, 2.40034350e-06, 1.36008135e-05, 8.53480438e-05,\n",
       "        1.20819038e-04, 1.63448761e-05, 1.61685067e-05, 1.13907664e-04,\n",
       "        1.16007474e-04, 4.73475528e-05, 6.86792186e-05, 4.17715883e-06,\n",
       "        5.41611031e-05, 4.94180467e-05, 1.90362567e-05, 7.53382489e-05,\n",
       "        1.66942276e-04, 2.25982582e-06, 5.42646971e-05, 6.26480193e-05,\n",
       "        1.92868694e-06, 1.32820284e-04, 1.95767062e-05, 9.34715896e-05,\n",
       "        4.96745782e-05, 3.53528999e-04, 4.24600932e-05, 1.37856204e-04,\n",
       "        1.95086430e-05, 7.04286384e-05, 5.10762270e-05, 5.04561313e-05,\n",
       "        6.11148999e-05, 8.06343619e-05, 3.31627837e-04, 2.48123076e-05,\n",
       "        5.52601396e-05, 1.55619341e-04, 8.99377833e-05, 3.23517760e-05,\n",
       "        1.87419448e-05, 2.13461202e-06, 4.49676402e-05, 5.50534054e-05,\n",
       "        6.34120994e-05, 6.61416970e-05, 3.21939601e-05, 4.29213308e-05,\n",
       "        1.33434340e-05, 1.12244003e-04, 2.93649625e-05, 1.18322892e-05,\n",
       "        5.46711218e-05, 5.38376393e-05, 5.04382379e-05, 6.50915732e-05,\n",
       "        6.64734943e-05, 8.63597248e-05, 1.12479973e-04, 5.26985102e-05,\n",
       "        5.65788136e-05, 5.83341617e-06, 6.50628533e-05, 1.24123469e-04,\n",
       "        2.56773157e-05, 8.93907024e-05, 1.35456806e-04, 1.56598724e-05,\n",
       "        9.09094013e-05, 2.42311172e-05, 3.25854619e-05, 3.66141392e-06,\n",
       "        2.14939870e-05, 9.23857197e-05, 1.00091697e-04, 9.82170422e-05,\n",
       "        1.47202542e-04, 6.67651036e-05, 2.03760725e-06, 7.76052145e-05,\n",
       "        2.24489799e-04, 1.03731581e-04, 2.51765504e-05, 8.18982777e-05,\n",
       "        1.21868850e-04, 1.52298340e-04, 1.39427055e-04, 2.30611780e-05,\n",
       "        1.06951779e-04, 3.76885556e-04, 2.23453036e-06, 7.56959427e-05,\n",
       "        9.43755304e-05, 9.85169803e-05, 7.51778203e-05, 2.28745698e-05,\n",
       "        7.58613901e-05, 1.65225279e-05, 1.34400425e-05, 1.35795035e-04,\n",
       "        6.41778176e-05, 3.90194422e-05, 6.35868385e-05, 3.70769638e-06,\n",
       "        1.59118666e-04, 3.73608532e-05, 2.76498129e-05, 4.65007920e-06,\n",
       "        5.23246170e-05, 1.43070220e-05, 1.94285988e-04, 2.71717696e-05,\n",
       "        2.88716083e-04, 6.66066584e-05, 6.03736103e-05, 1.46849232e-04,\n",
       "        3.67846413e-05, 5.26460184e-05, 1.46223497e-05, 4.87091900e-05,\n",
       "        7.53489320e-05, 4.99044657e-05, 4.13218949e-05, 3.01542107e-05,\n",
       "        6.38245067e-05, 6.61348213e-05, 8.60984388e-05, 2.56521551e-05,\n",
       "        1.81332338e-05, 1.95617177e-05, 1.66713073e-05, 1.62917889e-05,\n",
       "        5.24847189e-05, 3.20915304e-05, 8.83040107e-05, 7.36607078e-05,\n",
       "        1.60007112e-06, 2.19854975e-04, 7.82923053e-05, 7.23595321e-05,\n",
       "        3.07345870e-05, 5.17768310e-05, 9.92073431e-06, 1.49422841e-05,\n",
       "        6.32799740e-05, 1.65204595e-04, 3.46759312e-05, 5.23989582e-05,\n",
       "        2.23185261e-05, 4.04800671e-04, 5.22991739e-04, 7.76673909e-06,\n",
       "        3.07328854e-06, 5.67281926e-05, 1.75203755e-05, 2.24250468e-04,\n",
       "        6.63613281e-04, 7.24039188e-06, 6.57378436e-06, 2.85623468e-05,\n",
       "        8.55435762e-05, 1.31483590e-04, 1.70179461e-04, 2.92388715e-04,\n",
       "        1.39907841e-04, 2.63879141e-04]),\n",
       " 'mean_score_time': array([0.00516143, 0.00220699, 0.00423551, 0.00183396, 0.00419564,\n",
       "        0.00210829, 0.00396638, 0.00190892, 0.00387526, 0.00176878,\n",
       "        0.00384703, 0.00175414, 0.00395021, 0.00237932, 0.0040463 ,\n",
       "        0.00184522, 0.00405478, 0.00186434, 0.00396953, 0.00189281,\n",
       "        0.00400581, 0.0018456 , 0.00401878, 0.00189633, 0.00390682,\n",
       "        0.0019804 , 0.00400057, 0.00186429, 0.00413423, 0.00200052,\n",
       "        0.00404811, 0.00203981, 0.00399351, 0.00201263, 0.00415077,\n",
       "        0.00205321, 0.00405073, 0.00213432, 0.00410547, 0.00204167,\n",
       "        0.00409989, 0.00200949, 0.00427337, 0.00202956, 0.00411749,\n",
       "        0.00249748, 0.00401864, 0.00211082, 0.00409088, 0.00208201,\n",
       "        0.00409322, 0.00210767, 0.00418644, 0.00207963, 0.00530872,\n",
       "        0.00224156, 0.00426869, 0.00252156, 0.00525222, 0.00229325,\n",
       "        0.00427961, 0.00228329, 0.00422587, 0.00223937, 0.00435562,\n",
       "        0.00224519, 0.00420103, 0.00225544, 0.00422091, 0.00221148,\n",
       "        0.00424747, 0.002315  , 0.0041738 , 0.00229793, 0.00432763,\n",
       "        0.00222669, 0.00422025, 0.00231962, 0.0043015 , 0.00248389,\n",
       "        0.00436382, 0.00238662, 0.00429087, 0.00231385, 0.0043663 ,\n",
       "        0.00240855, 0.00423884, 0.00237899, 0.0042747 , 0.00240345,\n",
       "        0.00437517, 0.00245328, 0.00434976, 0.0023993 , 0.00434012,\n",
       "        0.00244732, 0.00428634, 0.00245385, 0.00441427, 0.00247111,\n",
       "        0.00538263, 0.00279856, 0.00464959, 0.00261636, 0.0045898 ,\n",
       "        0.00263052, 0.00455046, 0.00265484, 0.00462203, 0.00262799,\n",
       "        0.00455942, 0.00261607, 0.00457339, 0.00259295, 0.0044776 ,\n",
       "        0.0026607 , 0.00456758, 0.00266852, 0.00455494, 0.00276327,\n",
       "        0.00462499, 0.00272284, 0.00454359, 0.002777  , 0.00461063,\n",
       "        0.00281081, 0.00457525, 0.00283742, 0.00462837, 0.00266376,\n",
       "        0.00472283, 0.00282612, 0.00493522, 0.00281243, 0.0049758 ,\n",
       "        0.00307813, 0.0051312 , 0.00297689, 0.00488739, 0.00306878,\n",
       "        0.00586214, 0.00294328, 0.00476618, 0.002912  , 0.00475235,\n",
       "        0.00318317, 0.00521331, 0.00306544, 0.00501709, 0.00299602,\n",
       "        0.00498643, 0.0030467 , 0.00500641, 0.00300155, 0.00536804,\n",
       "        0.00305195, 0.00499606, 0.00309315, 0.00505462, 0.00312161,\n",
       "        0.00489244, 0.00319448, 0.00494604, 0.00308757, 0.00488887,\n",
       "        0.00314775, 0.00491161, 0.00309167, 0.00493078, 0.00394845,\n",
       "        0.00554647, 0.0032825 , 0.00514812, 0.00320244, 0.00528116,\n",
       "        0.00424385, 0.00636373, 0.00344553, 0.00543489, 0.00348139,\n",
       "        0.00507236, 0.00326452, 0.00615997, 0.00363836, 0.00579023,\n",
       "        0.00361309]),\n",
       " 'std_score_time': array([1.50400563e-04, 1.23206676e-04, 2.38615908e-04, 7.24478704e-06,\n",
       "        5.24250741e-05, 3.50167516e-04, 7.03846858e-05, 2.20532809e-04,\n",
       "        5.96736509e-05, 4.30220760e-05, 9.66606200e-05, 2.62315051e-05,\n",
       "        2.39256179e-04, 4.78735972e-04, 4.82432439e-05, 3.58525104e-05,\n",
       "        2.18463817e-04, 6.76706692e-05, 6.80456148e-05, 8.72282320e-05,\n",
       "        9.05785537e-05, 3.41965722e-05, 1.42174338e-04, 8.23579910e-05,\n",
       "        1.18610269e-04, 1.15521574e-04, 1.66334758e-04, 4.69059940e-05,\n",
       "        2.45532264e-04, 1.32283549e-04, 1.25947399e-04, 1.97272932e-04,\n",
       "        7.51326513e-05, 1.06263522e-04, 2.14170368e-04, 1.54755470e-04,\n",
       "        9.36507450e-05, 1.48149322e-04, 1.28311608e-04, 6.46905837e-05,\n",
       "        8.54110260e-05, 1.04280765e-04, 2.14217118e-04, 1.13257568e-04,\n",
       "        3.10870144e-04, 6.66003281e-04, 3.55007106e-05, 9.23230625e-05,\n",
       "        1.09218882e-04, 3.65670993e-05, 1.00324929e-04, 8.73643755e-05,\n",
       "        1.76419206e-04, 5.57254353e-05, 7.32873716e-04, 4.08931721e-05,\n",
       "        4.88429773e-05, 2.66595190e-04, 3.40724945e-04, 4.14515504e-05,\n",
       "        2.62195406e-05, 3.76053144e-05, 8.53791013e-05, 8.06563534e-05,\n",
       "        2.50016340e-04, 1.38334643e-04, 7.77011380e-05, 1.13522600e-04,\n",
       "        1.07358422e-04, 6.50001985e-05, 2.40853342e-04, 9.99386754e-05,\n",
       "        1.56973634e-04, 1.37090426e-04, 1.40095747e-04, 5.05194511e-05,\n",
       "        1.14395709e-04, 7.06756319e-05, 1.91243768e-04, 2.81623126e-04,\n",
       "        3.49457860e-04, 1.16537226e-04, 5.95335345e-05, 2.05051067e-05,\n",
       "        1.61986474e-04, 1.26745738e-04, 7.11763120e-05, 9.69707187e-05,\n",
       "        9.38884494e-05, 7.74665074e-05, 1.43493715e-04, 1.04702995e-04,\n",
       "        1.20205380e-04, 1.17778836e-04, 1.59705457e-04, 1.55495961e-04,\n",
       "        1.22335767e-04, 1.09387982e-04, 2.22586717e-04, 9.35337205e-05,\n",
       "        1.08270955e-03, 1.59073977e-04, 1.21523276e-04, 8.82659455e-05,\n",
       "        2.15423661e-04, 9.35634703e-05, 7.60671105e-05, 8.07884302e-05,\n",
       "        9.94153902e-05, 9.10432617e-05, 2.22679308e-04, 1.13136045e-04,\n",
       "        2.48928563e-04, 9.29924887e-05, 1.18493468e-04, 1.34156200e-04,\n",
       "        8.09446210e-05, 1.19613496e-04, 2.48181597e-04, 2.44687630e-04,\n",
       "        2.40564635e-04, 1.71843512e-04, 1.20288295e-04, 1.28407528e-04,\n",
       "        1.33972964e-04, 1.35275903e-04, 9.02895912e-05, 6.30608804e-05,\n",
       "        5.19716192e-05, 6.99244909e-05, 8.18953070e-05, 1.29882127e-04,\n",
       "        1.75961466e-04, 6.83077176e-05, 1.90870773e-04, 1.31362934e-04,\n",
       "        1.10718405e-04, 1.58024726e-04, 4.72971987e-05, 3.17240754e-04,\n",
       "        1.06265705e-03, 8.40674864e-05, 1.25514681e-04, 2.48502165e-05,\n",
       "        1.29496313e-04, 3.41485538e-04, 1.32979565e-04, 1.24285993e-04,\n",
       "        1.44143259e-04, 5.93798021e-05, 1.20364939e-04, 4.80791386e-05,\n",
       "        1.78374233e-04, 1.28727452e-04, 4.57978481e-04, 1.07405747e-04,\n",
       "        1.49723982e-04, 1.28571657e-04, 2.41102872e-04, 1.74625228e-04,\n",
       "        1.36692639e-04, 2.70769477e-04, 1.64311429e-04, 1.45148197e-04,\n",
       "        2.04546167e-04, 2.05848155e-04, 1.13908243e-04, 1.31733426e-04,\n",
       "        2.22947272e-04, 1.19359841e-03, 5.28982447e-04, 6.09491159e-05,\n",
       "        9.38662636e-05, 1.26764448e-04, 4.79945006e-04, 3.08068137e-04,\n",
       "        7.92773699e-04, 6.47857644e-05, 7.28245403e-05, 8.61229160e-05,\n",
       "        2.94491209e-04, 2.88643857e-04, 3.02422043e-04, 1.97967869e-04,\n",
       "        1.94191194e-04, 3.53674129e-04]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 1, 3, 3, 5, 5, 7, 7, 9, 9, 11, 11, 13, 13, 15, 15,\n",
       "                    17, 17, 19, 19, 21, 21, 23, 23, 25, 25, 27, 27, 29, 29,\n",
       "                    31, 31, 33, 33, 35, 35, 37, 37, 39, 39, 41, 41, 43, 43,\n",
       "                    45, 45, 47, 47, 49, 49, 51, 51, 53, 53, 55, 55, 57, 57,\n",
       "                    59, 59, 61, 61, 63, 63, 65, 65, 67, 67, 69, 69, 71, 71,\n",
       "                    73, 73, 75, 75, 77, 77, 79, 79, 81, 81, 83, 83, 85, 85,\n",
       "                    87, 87, 89, 89, 91, 91, 93, 93, 95, 95, 97, 97, 99, 99,\n",
       "                    101, 101, 103, 103, 105, 105, 107, 107, 109, 109, 111,\n",
       "                    111, 113, 113, 115, 115, 117, 117, 119, 119, 121, 121,\n",
       "                    123, 123, 125, 125, 127, 127, 129, 129, 131, 131, 133,\n",
       "                    133, 135, 135, 137, 137, 139, 139, 141, 141, 143, 143,\n",
       "                    145, 145, 147, 147, 149, 149, 151, 151, 153, 153, 155,\n",
       "                    155, 157, 157, 159, 159, 161, 161, 163, 163, 165, 165,\n",
       "                    167, 167, 169, 169, 171, 171, 173, 173, 175, 175, 177,\n",
       "                    177, 179, 179, 181, 181, 183, 183, 185, 185],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'n_neighbors': 11, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 11, 'weights': 'distance'},\n",
       "  {'n_neighbors': 13, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 13, 'weights': 'distance'},\n",
       "  {'n_neighbors': 15, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 15, 'weights': 'distance'},\n",
       "  {'n_neighbors': 17, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 17, 'weights': 'distance'},\n",
       "  {'n_neighbors': 19, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 19, 'weights': 'distance'},\n",
       "  {'n_neighbors': 21, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 21, 'weights': 'distance'},\n",
       "  {'n_neighbors': 23, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 23, 'weights': 'distance'},\n",
       "  {'n_neighbors': 25, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 25, 'weights': 'distance'},\n",
       "  {'n_neighbors': 27, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 27, 'weights': 'distance'},\n",
       "  {'n_neighbors': 29, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 29, 'weights': 'distance'},\n",
       "  {'n_neighbors': 31, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 31, 'weights': 'distance'},\n",
       "  {'n_neighbors': 33, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 33, 'weights': 'distance'},\n",
       "  {'n_neighbors': 35, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 35, 'weights': 'distance'},\n",
       "  {'n_neighbors': 37, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 37, 'weights': 'distance'},\n",
       "  {'n_neighbors': 39, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 39, 'weights': 'distance'},\n",
       "  {'n_neighbors': 41, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 41, 'weights': 'distance'},\n",
       "  {'n_neighbors': 43, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 43, 'weights': 'distance'},\n",
       "  {'n_neighbors': 45, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 45, 'weights': 'distance'},\n",
       "  {'n_neighbors': 47, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 47, 'weights': 'distance'},\n",
       "  {'n_neighbors': 49, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 49, 'weights': 'distance'},\n",
       "  {'n_neighbors': 51, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 51, 'weights': 'distance'},\n",
       "  {'n_neighbors': 53, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 53, 'weights': 'distance'},\n",
       "  {'n_neighbors': 55, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 55, 'weights': 'distance'},\n",
       "  {'n_neighbors': 57, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 57, 'weights': 'distance'},\n",
       "  {'n_neighbors': 59, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 59, 'weights': 'distance'},\n",
       "  {'n_neighbors': 61, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 61, 'weights': 'distance'},\n",
       "  {'n_neighbors': 63, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 63, 'weights': 'distance'},\n",
       "  {'n_neighbors': 65, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 65, 'weights': 'distance'},\n",
       "  {'n_neighbors': 67, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 67, 'weights': 'distance'},\n",
       "  {'n_neighbors': 69, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 69, 'weights': 'distance'},\n",
       "  {'n_neighbors': 71, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 71, 'weights': 'distance'},\n",
       "  {'n_neighbors': 73, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 73, 'weights': 'distance'},\n",
       "  {'n_neighbors': 75, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 75, 'weights': 'distance'},\n",
       "  {'n_neighbors': 77, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 77, 'weights': 'distance'},\n",
       "  {'n_neighbors': 79, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 79, 'weights': 'distance'},\n",
       "  {'n_neighbors': 81, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 81, 'weights': 'distance'},\n",
       "  {'n_neighbors': 83, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 83, 'weights': 'distance'},\n",
       "  {'n_neighbors': 85, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 85, 'weights': 'distance'},\n",
       "  {'n_neighbors': 87, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 87, 'weights': 'distance'},\n",
       "  {'n_neighbors': 89, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 89, 'weights': 'distance'},\n",
       "  {'n_neighbors': 91, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 91, 'weights': 'distance'},\n",
       "  {'n_neighbors': 93, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 93, 'weights': 'distance'},\n",
       "  {'n_neighbors': 95, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 95, 'weights': 'distance'},\n",
       "  {'n_neighbors': 97, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 97, 'weights': 'distance'},\n",
       "  {'n_neighbors': 99, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 99, 'weights': 'distance'},\n",
       "  {'n_neighbors': 101, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 101, 'weights': 'distance'},\n",
       "  {'n_neighbors': 103, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 103, 'weights': 'distance'},\n",
       "  {'n_neighbors': 105, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 105, 'weights': 'distance'},\n",
       "  {'n_neighbors': 107, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 107, 'weights': 'distance'},\n",
       "  {'n_neighbors': 109, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 109, 'weights': 'distance'},\n",
       "  {'n_neighbors': 111, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 111, 'weights': 'distance'},\n",
       "  {'n_neighbors': 113, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 113, 'weights': 'distance'},\n",
       "  {'n_neighbors': 115, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 115, 'weights': 'distance'},\n",
       "  {'n_neighbors': 117, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 117, 'weights': 'distance'},\n",
       "  {'n_neighbors': 119, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 119, 'weights': 'distance'},\n",
       "  {'n_neighbors': 121, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 121, 'weights': 'distance'},\n",
       "  {'n_neighbors': 123, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 123, 'weights': 'distance'},\n",
       "  {'n_neighbors': 125, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 125, 'weights': 'distance'},\n",
       "  {'n_neighbors': 127, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 127, 'weights': 'distance'},\n",
       "  {'n_neighbors': 129, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 129, 'weights': 'distance'},\n",
       "  {'n_neighbors': 131, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 131, 'weights': 'distance'},\n",
       "  {'n_neighbors': 133, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 133, 'weights': 'distance'},\n",
       "  {'n_neighbors': 135, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 135, 'weights': 'distance'},\n",
       "  {'n_neighbors': 137, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 137, 'weights': 'distance'},\n",
       "  {'n_neighbors': 139, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 139, 'weights': 'distance'},\n",
       "  {'n_neighbors': 141, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 141, 'weights': 'distance'},\n",
       "  {'n_neighbors': 143, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 143, 'weights': 'distance'},\n",
       "  {'n_neighbors': 145, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 145, 'weights': 'distance'},\n",
       "  {'n_neighbors': 147, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 147, 'weights': 'distance'},\n",
       "  {'n_neighbors': 149, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 149, 'weights': 'distance'},\n",
       "  {'n_neighbors': 151, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 151, 'weights': 'distance'},\n",
       "  {'n_neighbors': 153, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 153, 'weights': 'distance'},\n",
       "  {'n_neighbors': 155, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 155, 'weights': 'distance'},\n",
       "  {'n_neighbors': 157, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 157, 'weights': 'distance'},\n",
       "  {'n_neighbors': 159, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 159, 'weights': 'distance'},\n",
       "  {'n_neighbors': 161, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 161, 'weights': 'distance'},\n",
       "  {'n_neighbors': 163, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 163, 'weights': 'distance'},\n",
       "  {'n_neighbors': 165, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 165, 'weights': 'distance'},\n",
       "  {'n_neighbors': 167, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 167, 'weights': 'distance'},\n",
       "  {'n_neighbors': 169, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 169, 'weights': 'distance'},\n",
       "  {'n_neighbors': 171, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 171, 'weights': 'distance'},\n",
       "  {'n_neighbors': 173, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 173, 'weights': 'distance'},\n",
       "  {'n_neighbors': 175, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 175, 'weights': 'distance'},\n",
       "  {'n_neighbors': 177, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 177, 'weights': 'distance'},\n",
       "  {'n_neighbors': 179, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 179, 'weights': 'distance'},\n",
       "  {'n_neighbors': 181, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 181, 'weights': 'distance'},\n",
       "  {'n_neighbors': 183, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 183, 'weights': 'distance'},\n",
       "  {'n_neighbors': 185, 'weights': 'uniform'},\n",
       "  {'n_neighbors': 185, 'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.37037037, 0.37037037, 0.2962963 , 0.22222222, 0.40740741,\n",
       "        0.18518519, 0.25925926, 0.18518519, 0.14814815, 0.14814815,\n",
       "        0.11111111, 0.14814815, 0.18518519, 0.14814815, 0.14814815,\n",
       "        0.14814815, 0.03703704, 0.14814815, 0.07407407, 0.14814815,\n",
       "        0.03703704, 0.14814815, 0.07407407, 0.14814815, 0.07407407,\n",
       "        0.14814815, 0.18518519, 0.14814815, 0.03703704, 0.14814815,\n",
       "        0.03703704, 0.14814815, 0.03703704, 0.14814815, 0.03703704,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.03703704, 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815]),\n",
       " 'split1_test_score': array([0.37037037, 0.37037037, 0.37037037, 0.37037037, 0.18518519,\n",
       "        0.14814815, 0.14814815, 0.14814815, 0.11111111, 0.14814815,\n",
       "        0.18518519, 0.14814815, 0.11111111, 0.14814815, 0.11111111,\n",
       "        0.14814815, 0.11111111, 0.14814815, 0.07407407, 0.14814815,\n",
       "        0.07407407, 0.14814815, 0.11111111, 0.14814815, 0.11111111,\n",
       "        0.14814815, 0.11111111, 0.14814815, 0.07407407, 0.14814815,\n",
       "        0.11111111, 0.14814815, 0.07407407, 0.14814815, 0.07407407,\n",
       "        0.14814815, 0.07407407, 0.14814815, 0.07407407, 0.14814815,\n",
       "        0.07407407, 0.14814815, 0.07407407, 0.14814815, 0.07407407,\n",
       "        0.14814815, 0.07407407, 0.14814815, 0.07407407, 0.14814815,\n",
       "        0.07407407, 0.14814815, 0.07407407, 0.14814815, 0.11111111,\n",
       "        0.14814815, 0.11111111, 0.14814815, 0.14814815, 0.14814815,\n",
       "        0.11111111, 0.14814815, 0.07407407, 0.14814815, 0.11111111,\n",
       "        0.14814815, 0.11111111, 0.14814815, 0.11111111, 0.14814815,\n",
       "        0.11111111, 0.14814815, 0.11111111, 0.14814815, 0.11111111,\n",
       "        0.14814815, 0.03703704, 0.14814815, 0.03703704, 0.14814815,\n",
       "        0.03703704, 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.03703704, 0.11111111,\n",
       "        0.        , 0.14814815, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111, 0.        , 0.11111111, 0.        , 0.11111111,\n",
       "        0.        , 0.11111111, 0.        , 0.11111111, 0.        ,\n",
       "        0.11111111]),\n",
       " 'split2_test_score': array([0.37037037, 0.37037037, 0.33333333, 0.33333333, 0.22222222,\n",
       "        0.2962963 , 0.2962963 , 0.2962963 , 0.40740741, 0.25925926,\n",
       "        0.25925926, 0.25925926, 0.25925926, 0.25925926, 0.25925926,\n",
       "        0.25925926, 0.18518519, 0.25925926, 0.25925926, 0.25925926,\n",
       "        0.25925926, 0.25925926, 0.14814815, 0.25925926, 0.25925926,\n",
       "        0.22222222, 0.03703704, 0.22222222, 0.18518519, 0.18518519,\n",
       "        0.        , 0.18518519, 0.        , 0.18518519, 0.        ,\n",
       "        0.18518519, 0.        , 0.18518519, 0.        , 0.18518519,\n",
       "        0.        , 0.18518519, 0.03703704, 0.18518519, 0.03703704,\n",
       "        0.18518519, 0.        , 0.18518519, 0.        , 0.18518519,\n",
       "        0.03703704, 0.18518519, 0.03703704, 0.18518519, 0.03703704,\n",
       "        0.14814815, 0.        , 0.14814815, 0.03703704, 0.14814815,\n",
       "        0.03703704, 0.14814815, 0.03703704, 0.14814815, 0.03703704,\n",
       "        0.14814815, 0.03703704, 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815, 0.        , 0.14814815, 0.        , 0.14814815,\n",
       "        0.        , 0.14814815, 0.        , 0.14814815, 0.        ,\n",
       "        0.14814815]),\n",
       " 'split3_test_score': array([0.26923077, 0.26923077, 0.26923077, 0.26923077, 0.23076923,\n",
       "        0.26923077, 0.26923077, 0.30769231, 0.15384615, 0.23076923,\n",
       "        0.15384615, 0.23076923, 0.19230769, 0.23076923, 0.11538462,\n",
       "        0.19230769, 0.15384615, 0.19230769, 0.03846154, 0.19230769,\n",
       "        0.11538462, 0.19230769, 0.07692308, 0.19230769, 0.07692308,\n",
       "        0.19230769, 0.07692308, 0.19230769, 0.07692308, 0.19230769,\n",
       "        0.11538462, 0.19230769, 0.07692308, 0.19230769, 0.07692308,\n",
       "        0.19230769, 0.07692308, 0.19230769, 0.07692308, 0.19230769,\n",
       "        0.03846154, 0.19230769, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.03846154, 0.15384615,\n",
       "        0.03846154, 0.15384615, 0.03846154, 0.15384615, 0.        ,\n",
       "        0.15384615, 0.03846154, 0.15384615, 0.03846154, 0.15384615,\n",
       "        0.        , 0.15384615, 0.03846154, 0.15384615, 0.        ,\n",
       "        0.15384615, 0.03846154, 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.03846154, 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615]),\n",
       " 'split4_test_score': array([0.23076923, 0.23076923, 0.34615385, 0.38461538, 0.30769231,\n",
       "        0.38461538, 0.19230769, 0.34615385, 0.19230769, 0.30769231,\n",
       "        0.11538462, 0.23076923, 0.11538462, 0.23076923, 0.07692308,\n",
       "        0.23076923, 0.07692308, 0.23076923, 0.15384615, 0.23076923,\n",
       "        0.15384615, 0.23076923, 0.11538462, 0.23076923, 0.07692308,\n",
       "        0.23076923, 0.07692308, 0.23076923, 0.07692308, 0.23076923,\n",
       "        0.07692308, 0.23076923, 0.07692308, 0.23076923, 0.07692308,\n",
       "        0.23076923, 0.07692308, 0.23076923, 0.07692308, 0.23076923,\n",
       "        0.07692308, 0.23076923, 0.07692308, 0.23076923, 0.07692308,\n",
       "        0.23076923, 0.07692308, 0.23076923, 0.11538462, 0.23076923,\n",
       "        0.11538462, 0.23076923, 0.07692308, 0.23076923, 0.07692308,\n",
       "        0.23076923, 0.        , 0.23076923, 0.03846154, 0.23076923,\n",
       "        0.        , 0.19230769, 0.        , 0.23076923, 0.07692308,\n",
       "        0.23076923, 0.07692308, 0.23076923, 0.07692308, 0.23076923,\n",
       "        0.07692308, 0.23076923, 0.07692308, 0.19230769, 0.07692308,\n",
       "        0.19230769, 0.07692308, 0.19230769, 0.07692308, 0.19230769,\n",
       "        0.07692308, 0.19230769, 0.        , 0.19230769, 0.        ,\n",
       "        0.19230769, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615, 0.        , 0.15384615, 0.        , 0.15384615,\n",
       "        0.        , 0.15384615, 0.        , 0.15384615, 0.        ,\n",
       "        0.15384615]),\n",
       " 'mean_test_score': array([0.32222222, 0.32222222, 0.32307692, 0.31595442, 0.27065527,\n",
       "        0.25669516, 0.23304843, 0.25669516, 0.2025641 , 0.21880342,\n",
       "        0.16495726, 0.2034188 , 0.17264957, 0.2034188 , 0.14216524,\n",
       "        0.1957265 , 0.11282051, 0.1957265 , 0.11994302, 0.1957265 ,\n",
       "        0.12792023, 0.1957265 , 0.10512821, 0.1957265 , 0.11965812,\n",
       "        0.18831909, 0.0974359 , 0.18831909, 0.09002849, 0.18091168,\n",
       "        0.06809117, 0.18091168, 0.05299145, 0.18091168, 0.05299145,\n",
       "        0.18091168, 0.04558405, 0.18091168, 0.04558405, 0.18091168,\n",
       "        0.03789174, 0.18091168, 0.04501425, 0.17321937, 0.03760684,\n",
       "        0.17321937, 0.03019943, 0.17321937, 0.04558405, 0.17321937,\n",
       "        0.05299145, 0.17321937, 0.04529915, 0.17321937, 0.04501425,\n",
       "        0.16581197, 0.02991453, 0.16581197, 0.05242165, 0.16581197,\n",
       "        0.02962963, 0.15811966, 0.02991453, 0.16581197, 0.04501425,\n",
       "        0.16581197, 0.05270655, 0.16581197, 0.03760684, 0.16581197,\n",
       "        0.03760684, 0.16581197, 0.04529915, 0.15811966, 0.03760684,\n",
       "        0.15811966, 0.02279202, 0.15811966, 0.02279202, 0.15811966,\n",
       "        0.02279202, 0.15811966, 0.        , 0.15811966, 0.        ,\n",
       "        0.15071225, 0.        , 0.14301994, 0.00740741, 0.14301994,\n",
       "        0.        , 0.15042735, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994, 0.        , 0.14301994, 0.        , 0.14301994,\n",
       "        0.        , 0.14301994, 0.        , 0.14301994, 0.        ,\n",
       "        0.14301994]),\n",
       " 'std_test_score': array([0.06021042, 0.06021042, 0.03603059, 0.06155692, 0.07913871,\n",
       "        0.0836482 , 0.05452399, 0.0762469 , 0.10560697, 0.06271431,\n",
       "        0.05437343, 0.04631185, 0.05497468, 0.04631185, 0.06274537,\n",
       "        0.04427977, 0.05282884, 0.04427977, 0.0792535 , 0.04427977,\n",
       "        0.07647012, 0.04427977, 0.02739194, 0.04427977, 0.07112243,\n",
       "        0.03519874, 0.04975243, 0.03519874, 0.04992181, 0.03092185,\n",
       "        0.04419537, 0.03092185, 0.03050429, 0.03092185, 0.03050429,\n",
       "        0.03092185, 0.03723375, 0.03092185, 0.03723375, 0.03092185,\n",
       "        0.03377721, 0.03092185, 0.02834149, 0.03189866, 0.03377721,\n",
       "        0.03189866, 0.03699757, 0.03189866, 0.04447548, 0.03189866,\n",
       "        0.03901574, 0.03189866, 0.02826693, 0.03189866, 0.04359626,\n",
       "        0.03255352, 0.04324482, 0.03255352, 0.05007604, 0.03255352,\n",
       "        0.04319224, 0.01723588, 0.02779786, 0.03255352, 0.04359626,\n",
       "        0.03255352, 0.03801044, 0.03255352, 0.04731061, 0.03255352,\n",
       "        0.04731061, 0.03255352, 0.04354783, 0.01723588, 0.04731061,\n",
       "        0.01723588, 0.03063175, 0.01723588, 0.03063175, 0.01723588,\n",
       "        0.03063175, 0.01723588, 0.        , 0.01723588, 0.        ,\n",
       "        0.02577364, 0.        , 0.01615663, 0.01481481, 0.01615663,\n",
       "        0.        , 0.00279144, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663, 0.        , 0.01615663, 0.        , 0.01615663,\n",
       "        0.        , 0.01615663, 0.        , 0.01615663, 0.        ,\n",
       "        0.01615663]),\n",
       " 'rank_test_score': array([  2,   2,   1,   4,   5,   7,   8,   6,  12,   9,  42,  10,  33,\n",
       "         10, 101,  13, 105,  13, 103,  13, 102,  13, 106,  13, 104,  18,\n",
       "        107,  18, 108,  20, 109,  20, 110,  20, 110,  20, 115,  20, 115,\n",
       "         20, 123,  20, 120,  27, 124,  27, 128,  27, 115,  27, 110,  27,\n",
       "        118,  27, 120,  34, 129,  34, 114,  34, 131,  43, 129,  34, 120,\n",
       "         34, 113,  34, 124,  34, 124,  34, 118,  43, 124,  43, 132,  43,\n",
       "        132,  43, 132,  43, 136,  43, 136,  50, 136,  52, 135,  52, 136,\n",
       "         51, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52,\n",
       "        136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,\n",
       "         52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52,\n",
       "        136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,\n",
       "         52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52,\n",
       "        136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,\n",
       "         52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52, 136,  52,\n",
       "        136,  52, 136,  52], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# params = {'kernel': ['poly'], 'gamma': [10]}\n",
    "# svc_grid = GridSearchCV(svc, cv = 5, param_grid = params, scoring=scorer).fit(X_train, y_train)\n",
    "# svc_train = svc_grid.score(X_train, y_train)\n",
    "# svc_test = svc_grid.score(X_test, y_test)\n",
    "# svc_time = np.mean(svc_grid.cv_results_['mean_fit_time']) + np.mean(svc_grid.cv_results_['mean_score_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 482 ms, sys: 2.81 ms, total: 485 ms\n",
      "Wall time: 484 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'kernel': ['rbf', 'linear', 'sigmoid'], 'gamma': [0.1, 1.0, 10.0]}\n",
    "svc_grid = GridSearchCV(svc, cv = 5, param_grid = params, scoring=scorer).fit(X_train, y_train)\n",
    "svc_train = svc_grid.score(X_train, y_train)\n",
    "svc_test = svc_grid.score(X_test, y_test)\n",
    "svc_time = np.mean(svc_grid.cv_results_['mean_fit_time']) #+ np.mean(svc_grid.cv_results_['mean_score_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=0.1, kernel='sigmoid')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0077682 , 0.01147275, 0.00503454, 0.0061317 , 0.01018887,\n",
       "        0.00402727, 0.0062129 , 0.00998082, 0.00331693]),\n",
       " 'std_fit_time': array([0.00032591, 0.00276214, 0.00038484, 0.00047707, 0.00252557,\n",
       "        0.00011998, 0.00075012, 0.00247375, 0.00012507]),\n",
       " 'mean_score_time': array([0.00480304, 0.00221863, 0.00246744, 0.00434809, 0.001826  ,\n",
       "        0.00202255, 0.00426493, 0.00202074, 0.00200138]),\n",
       " 'std_score_time': array([1.55588362e-04, 1.35759701e-04, 4.26826937e-04, 4.35453907e-04,\n",
       "        6.71317289e-05, 6.46469504e-05, 2.35090807e-04, 5.26473240e-04,\n",
       "        1.97110293e-04]),\n",
       " 'param_gamma': masked_array(data=[0.1, 0.1, 0.1, 1.0, 1.0, 1.0, 10.0, 10.0, 10.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'sigmoid', 'rbf', 'linear', 'sigmoid',\n",
       "                    'rbf', 'linear', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'gamma': 1.0, 'kernel': 'rbf'},\n",
       "  {'gamma': 1.0, 'kernel': 'linear'},\n",
       "  {'gamma': 1.0, 'kernel': 'sigmoid'},\n",
       "  {'gamma': 10.0, 'kernel': 'rbf'},\n",
       "  {'gamma': 10.0, 'kernel': 'linear'},\n",
       "  {'gamma': 10.0, 'kernel': 'sigmoid'}],\n",
       " 'split0_test_score': array([0.        , 0.        , 0.14814815, 0.14814815, 0.        ,\n",
       "        0.        , 0.14814815, 0.        , 0.        ]),\n",
       " 'split1_test_score': array([0.14814815, 0.        , 0.2962963 , 0.11111111, 0.        ,\n",
       "        0.        , 0.11111111, 0.        , 0.        ]),\n",
       " 'split2_test_score': array([0.        , 0.        , 0.2962963 , 0.14814815, 0.        ,\n",
       "        0.        , 0.14814815, 0.        , 0.        ]),\n",
       " 'split3_test_score': array([0.03846154, 0.        , 0.26923077, 0.15384615, 0.        ,\n",
       "        0.        , 0.15384615, 0.        , 0.        ]),\n",
       " 'split4_test_score': array([0.19230769, 0.        , 0.26923077, 0.19230769, 0.        ,\n",
       "        0.        , 0.15384615, 0.        , 0.        ]),\n",
       " 'mean_test_score': array([0.07578348, 0.        , 0.25584046, 0.15071225, 0.        ,\n",
       "        0.        , 0.14301994, 0.        , 0.        ]),\n",
       " 'std_test_score': array([0.07961625, 0.        , 0.05518983, 0.02577364, 0.        ,\n",
       "        0.        , 0.01615663, 0.        , 0.        ]),\n",
       " 'rank_test_score': array([4, 5, 1, 2, 5, 5, 3, 5, 5], dtype=int32)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataFrame\n",
    "Construct a DataFrame of the model results as follows:\n",
    "\n",
    "| model | train score | test score | average fit time |\n",
    "| ----- | -----   | -------   | ------- |\n",
    "| KNN | ? | ? | ? |\n",
    "| Logistic Regression | ? | ? | ? |\n",
    "| SVC | ? | ? | ? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>average fit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.443609</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.007126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train score  test score  average fit time\n",
       "0                  KNN     0.443609    0.222222          0.001148\n",
       "1  Logistic Regression     0.075188    0.066667          0.001956\n",
       "2                  SVC     0.263158    0.422222          0.007126"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'model':['KNN', 'Logistic Regression', 'SVC'],\n",
    "              'train score':[knn_train, lgr_train, svc_train],\n",
    "              'test score':[knn_test, lgr_test, svc_test],\n",
    "              'average fit time':[knn_time, lgr_time, svc_time]\n",
    "             })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {0: 'KNN', 1: 'Logistic Regression', 2: 'SVC'},\n",
       " 'train score': {0: 0.44360902255639095,\n",
       "  1: 0.07518796992481203,\n",
       "  2: 0.2631578947368421},\n",
       " 'test score': {0: 0.2222222222222222,\n",
       "  1: 0.06666666666666667,\n",
       "  2: 0.4222222222222222},\n",
       " 'average fit time': {0: 0.0011476726942164924,\n",
       "  1: 0.0019556999206542967,\n",
       "  2: 0.00712599754333496}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>average fit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.443609</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.006927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train score  test score  average fit time\n",
       "0                  KNN     0.443609    0.222222          0.001188\n",
       "1  Logistic Regression     0.075188    0.066667          0.001879\n",
       "2                  SVC     0.263158    0.422222          0.006927"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'model': {0: 'KNN', 1: 'Logistic Regression', 2: 'SVC'},\n",
    " 'train score': {0: 0.44360902255639095,\n",
    "  1: 0.07518796992481203,\n",
    "  2: 0.2631578947368421},\n",
    " 'test score': {0: 0.2222222222222222,\n",
    "  1: 0.06666666666666667,\n",
    "  2: 0.4222222222222222},\n",
    " 'average fit time': {0: 0.0011877864919682983,\n",
    "  1: 0.0018786191940307617,\n",
    "  2: 0.006927331288655599}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36864bacb9380889f0954b1091d54bdb",
     "grade": false,
     "grade_id": "cell-c2a5ca74d8cdd115",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>average fit time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.443609</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.006927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train score  test score  average fit time\n",
       "model                                                         \n",
       "KNN                     0.443609    0.222222          0.001188\n",
       "Logistic Regression     0.075188    0.066667          0.001879\n",
       "SVC                     0.263158    0.422222          0.006927"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "results_df = ''\n",
    "\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "res_dict = {'model': {0: 'KNN', 1: 'Logistic Regression', 2: 'SVC'},\n",
    " 'train score': {0: 0.44360902255639095,\n",
    "  1: 0.07518796992481203,\n",
    "  2: 0.2631578947368421},\n",
    " 'test score': {0: 0.2222222222222222,\n",
    "  1: 0.06666666666666667,\n",
    "  2: 0.4222222222222222},\n",
    " 'average fit time': {0: 0.0011877864919682983,\n",
    "  1: 0.0018786191940307617,\n",
    "  2: 0.006927331288655599}}\n",
    "results_df = pd.DataFrame(res_dict).set_index('model')\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(results_df))\n",
    "print(results_df.shape)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a93d04852c99fbf264fd9be78d16c89",
     "grade": true,
     "grade_id": "cell-a55e4dfa02723bd0",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 s, sys: 30.6 ms, total: 46.7 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svcp = SVC(gamma=0.1, kernel='poly').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.77\n",
      "Test Accuracy :  0.77\n",
      "CPU times: user 9.91 ms, sys: 1.43 ms, total: 11.3 ms\n",
      "Wall time: 9.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# scores\n",
    "svcp_train = svcp.score(X_train, y_train)\n",
    "svcp_test = svcp.score(X_test, y_test)\n",
    "print(f'Train Accuracy: {svcp_train: .2f}')\n",
    "print(f'Test Accuracy : {svcp_test: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
