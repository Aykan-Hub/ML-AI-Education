{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9885b323facdad84",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 9.7: Ridge vs. Sequential Feature Selection\n",
    "\n",
    "**Expected Time: 60 Minutes**\n",
    "\n",
    "**Total Points: 40**\n",
    "\n",
    "This activity focuses on comparing the results of a `Ridge` regression model with that of a `LinearRegression` model built using `SequentialFeatureSelector`.  Both of these approaches seek to limit the complexity of the model.  The `Ridge` estimator applies a penalty that shrinks the coefficients of the model while using the `SequentialFeatureSelector` selects a subset of features to build a model with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-686ed521942cdb92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc685dda5c83376a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d817f3e9eedd72c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Insurance Data\n",
    "\n",
    "For this example, we return to the insurance data with cubic features.  Below the train and test data is loaded and the train and test sets are determined.  Recall that the target feature has the logarithm applied to it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ba405bd2b8a324e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_cubic.csv')\n",
    "test = pd.read_csv('data/test_cubic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1be0f946b6eaeed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop('target_log', axis = 1), train['target_log']\n",
    "X_test, y_test = test.drop('target_log', axis = 1), test['target_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0efeb53332a708a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Feature Selection Pipeline\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To begin, use the pipeline below to construct a grid search over the `n_features_to_select` parameter of the `SequentialFeatureSelector` transformer.  Consider 2, 3, 4, and 5 features in your search.  Create the dictionary to be used in the search as `param_dict`.  \n",
    "\n",
    "Assign your grid to `selector_grid`, fit on the training data, and determine the mean squared error on the train and test set.  Assign the errors as floats to `selector_train_mse` and `selector_test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-805d087beeeb8b3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b {color: black;background-color: white;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b pre{padding: 0;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-toggleable {background-color: white;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-estimator:hover {background-color: #d4ebff;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-item {z-index: 1;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-parallel-item:only-child::after {width: 0;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-e78d8dc1-2d52-4a54-9e1b-65a7a7bf529b\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"81044b27-c8d6-4eb8-aaa1-cfd6db536c69\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"81044b27-c8d6-4eb8-aaa1-cfd6db536c69\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('selector',\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                ('model', LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"85595305-c2d8-4260-8c86-8027124b8fab\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"85595305-c2d8-4260-8c86-8027124b8fab\">selector: SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(estimator=LinearRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"875f8637-54b8-438a-a935-b3d2590a1203\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"875f8637-54b8-438a-a935-b3d2590a1203\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"59544aed-c5cf-452f-9752-21d160de4682\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"59544aed-c5cf-452f-9752-21d160de4682\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('selector',\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_pipe = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                         ('model', LinearRegression())])\n",
    "selector_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f580fcbb41258cf9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6031734290034884\n",
      "Test MSE: 0.5655875591380698\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "param_dict = {}\n",
    "selector_grid = ''\n",
    "selector_train_mse = ''\n",
    "selector_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "param_dict = {'selector__n_features_to_select': [2, 3, 4, 5]}\n",
    "selector_grid = GridSearchCV(selector_pipe, param_grid=param_dict)\n",
    "selector_grid.fit(X_train, y_train)\n",
    "train_preds = selector_grid.predict(X_train)\n",
    "test_preds = selector_grid.predict(X_test)\n",
    "selector_train_mse = mean_squared_error(y_train, train_preds)\n",
    "selector_test_mse = mean_squared_error(y_test, test_preds)\n",
    "### END SOLUTION\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {selector_train_mse}')\n",
    "print(f'Test MSE: {selector_test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b991b67a5ac0214d",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "selector_pipe_ = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                         ('model', LinearRegression())])\n",
    "param_dict_ = {'selector__n_features_to_select': [2, 3, 4, 5]}\n",
    "selector_grid_ = GridSearchCV(selector_pipe_, param_grid=param_dict_)\n",
    "selector_grid_.fit(X_train, y_train)\n",
    "train_preds_ = selector_grid_.predict(X_train)\n",
    "test_preds_ = selector_grid_.predict(X_test)\n",
    "selector_train_mse_ = mean_squared_error(y_train, train_preds_)\n",
    "selector_test_mse_ = mean_squared_error(y_test, test_preds_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert list(param_dict_.values()) == list(param_dict.values()), 'Check the parameter dictionary -- double underscores after selector'\n",
    "assert selector_train_mse == selector_train_mse_\n",
    "assert selector_test_mse == selector_test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-882a2f7363bd17d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Ridge Grid\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, construct a `Pipeline` that contains two steps -- `scaler` and `ridge` that first standard scales the data and then build a ridge regression model.  Assign your pipeline as `ridge_pipe`.  Use this to execute the grid search over the `alpha` hyperparameter of the `Ridge` estimator using the training data. Determine the mean squared error on the train and test data. \n",
    "\n",
    "Assign the errors as floats to `ridge_train_mse` and `ridge_test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b21362896fb19ee9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.5870277750390881\n",
      "Test MSE: 0.5532169282339892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 {color: black;background-color: white;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 pre{padding: 0;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-toggleable {background-color: white;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-item {z-index: 1;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-parallel-item:only-child::after {width: 0;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-7d20873d-d5e5-4ae9-97d7-7f06153ca2d5\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"06df2daf-b416-4979-be08-b997250615df\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"06df2daf-b416-4979-be08-b997250615df\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('scaler', StandardScaler()), ('ridge', Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4a444bea-4fff-44e2-83bb-3b4a0d51d21c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4a444bea-4fff-44e2-83bb-3b4a0d51d21c\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d587930c-10a0-47be-b2c9-eede4e00002b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d587930c-10a0-47be-b2c9-eede4e00002b\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('ridge', Ridge())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "ridge_param_dict = ''\n",
    "ridge_pipe = ''\n",
    "ridge_grid = ''\n",
    "ridge_train_mse = ''\n",
    "ridge_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                      ('ridge', Ridge())])\n",
    "ridge_grid = GridSearchCV(ridge_pipe, param_grid=ridge_param_dict)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "ridge_train_preds = ridge_grid.predict(X_train)\n",
    "ridge_test_preds = ridge_grid.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_train_preds)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_test_preds)\n",
    "### END SOLUTION\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {ridge_train_mse}')\n",
    "print(f'Test MSE: {ridge_test_mse}')\n",
    "ridge_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd8d23006d29b981",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ridge_param_dict_ = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe_ = Pipeline([('scaler', StandardScaler()), \n",
    "                      ('ridge', Ridge())])\n",
    "ridge_grid_ = GridSearchCV(ridge_pipe_, param_grid=ridge_param_dict_)\n",
    "ridge_grid_.fit(X_train, y_train)\n",
    "ridge_train_preds_ = ridge_grid_.predict(X_train)\n",
    "ridge_test_preds_ = ridge_grid_.predict(X_test)\n",
    "ridge_train_mse_ = mean_squared_error(y_train, ridge_train_preds_)\n",
    "ridge_test_mse_ = mean_squared_error(y_test, ridge_test_preds_)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(ridge_param_dict_['ridge__alpha'], ridge_param_dict['ridge__alpha'])\n",
    "assert ridge_train_mse == ridge_train_mse_\n",
    "assert ridge_test_mse == ridge_test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc0d54dcdc797fd0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Examining the \"best\" model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Your results should suggest that the model using the sequential feature selector and `LinearRegression` estimator.  This was fit with the object `selector_grid`.  One question we may have is what was the optimal number of features selected and what were they?  \n",
    "\n",
    "Use the `selector_grid` to extract both the feature names and their associated coefficients.  This will involve:\n",
    "\n",
    "- `.best_estimator_`: extract the best estimator/selector pair from your grid search\n",
    "- `.named_steps['selector']`: extract the selector from the pipeline\n",
    "- `.named_steps['model']`: extract the model from the pipeline\n",
    "- `.get_support()`: extract best features from selector.  This returns booleans as to whether feature was selected, we can use this to slice our train data.  \n",
    "\n",
    "```python\n",
    "X_train.columns[best_selector.get_support()]\n",
    "```\n",
    "\n",
    "- `.coef_`: coefficients from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-086dc1fb9b5bad93",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('selector',\n",
      "                 SequentialFeatureSelector(estimator=LinearRegression(),\n",
      "                                           n_features_to_select=2)),\n",
      "                ('model', LinearRegression())])\n",
      "Features from best selector: Index(['age', 'bmi children'], dtype='object').\n",
      "Coefficient values: \n",
      "===================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.00368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  bmi children\n",
       "model  0.032852       0.00368"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "best_estimator = ''\n",
    "best_selector = ''\n",
    "best_model = ''\n",
    "feature_names = ''\n",
    "coefs = ''\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_estimator = selector_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = selector_grid.best_estimator_.named_steps['model']\n",
    "feature_names = X_train.columns[best_selector.get_support()]\n",
    "coefs = best_model.coef_\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(best_estimator)\n",
    "print(f'Features from best selector: {feature_names}.')\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "pd.DataFrame([coefs.T], columns = feature_names, index = ['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-727135aa3ceb8535",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_estimator_ = selector_grid_.best_estimator_\n",
    "best_selector_ = best_estimator_.named_steps['selector']\n",
    "best_model_ = selector_grid_.best_estimator_.named_steps['model']\n",
    "feature_names_ = X_train.columns[best_selector_.get_support()]\n",
    "coefs_ = best_model_.coef_\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(coefs, coefs_)\n",
    "np.testing.assert_array_equal(feature_names, feature_names_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b828dc090256f1c7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 4\n",
    "\n",
    "#### Comparing observations \n",
    "\n",
    "**10 Points**\n",
    "\n",
    "According to your model, predict the billed costs for person 1 and person 2 below:\n",
    "\n",
    "- **Person 1**: Age = 30, bmi = 40, children = 0\n",
    "- **Person 2**: Age = 45, bmi = 50, children = 2\n",
    "\n",
    "Use the information from **Problem 3** and the model coefficients to make these predictions.\n",
    "\n",
    "Note that you will want to transform your predictions.  From your model the predictions are in terms of the logarithm of cost.  To transform the logarithm to the actual value, use `np.exp` -- the inverse of a logarithm. Assign your predictions as floats to `person1` and `person2` below.  Your solution will be checked to two decimal point accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51bce4efc95aa858",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between Person 1 and Person 2 is  3.66\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ages = [30, 45]\n",
    "bmis = [40, 50]\n",
    "childrens = [0, 2]\n",
    "person1 = ''\n",
    "person2 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "person1 = np.exp(coefs[0]*ages[0] + coefs[1]*(bmis[0]*childrens[0]))\n",
    "person2 = np.exp(coefs[0]*ages[1] + coefs[1]*(bmis[1]*childrens[1]))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'The difference between Person 1 and Person 2 is {person2 - person1: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5bb5e273c425e0a8",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ages = [30, 45]\n",
    "bmis = [40, 50]\n",
    "childrens = [0, 2]\n",
    "person1_ = np.exp(coefs[0]*ages[0] + coefs[1]*(bmis[0]*childrens[0]))\n",
    "person2_ = np.exp(coefs[0]*ages[1] + coefs[1]*(bmis[1]*childrens[1]))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert round(float(person1), 2) == round(float(person1_), 2), 'Person 1 is not correct.'\n",
    "assert round(float(person2), 2) == round(float(person2_), 2), 'Person 2 is not correct.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d53afcbf13ed189",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The models here could be revisited and more encoding of features and different polynomial terms can be incorporated.  More important is understanding how to construct the pipelines and interrogate the resulting models to understand what they say about your data.  Does having a higher body mass matter if one does not have children?  Does this seem reasonable?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
