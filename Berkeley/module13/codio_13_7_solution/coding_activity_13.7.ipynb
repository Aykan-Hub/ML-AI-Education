{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1bc26ee627d5273",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 13.7: Multi-Class Logistic Regression\n",
    "\n",
    "**Expected Time = 90 minutes**\n",
    "\n",
    "**Total Points = 60**\n",
    "\n",
    "This activity focuses on implementing `LogisticRegression` estimator using three approaches for multi class classification.  Two of these, one vs. rest and multinomial, are available using the estimator directly.  The third example, one vs. one, is implemented from the scikit-learn `multiclass` module.  Most important is that you can consider each of these models as options when building classification models and that you select the best depending on your identified metric.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b34f8d20a529570",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Below, the penguins data is loaded and the target feature for all classes is converted to a numeric value.  Thus, we have three classes where 0, 1, and 2 represent Adelie, Chinstrap, and Gentoo respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins').dropna()\n",
    "X = penguins.drop(['species', 'island', 'sex'], axis = 1)\n",
    "y = penguins.species\n",
    "y_num = pd.factorize(y)[0]\n",
    "categories = pd.factorize(y)[1]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=518)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b64d32b13d201e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### One vs. Rest Classification\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To begin, use the `LogisticRegression` estimator with the argument `multi_class = 'ovr'` and `random_state = 42` to fit a model on the training data named `ovr_lgr`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd11c6c0e63c7d0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ovr_lgr = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ovr_lgr = LogisticRegression(multi_class='ovr', random_state=42).fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "ovr_lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3a71c12cfa330275",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ovr_lgr_ = LogisticRegression(multi_class='ovr', random_state=42).fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ovr_lgr.multi_class == ovr_lgr_.multi_class\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-310233923fdbe4e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Examining the Probabilities\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Examine the predicted probabilities on the testing data.  Assign these to `ovr_probs` as an array below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-566e611d496dd3fc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ovr_probs = ovr_lgr.predict_proba(X_test)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ovr_probs = ovr_lgr.predict_proba(X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "pd.DataFrame(ovr_probs, columns = ['p(adelie)', 'p(gentoo)', 'p(chinstrap)']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fb931aac2c56b445",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ovr_lgr_ = LogisticRegression(multi_class='ovr', random_state=42).fit(X_train, y_train)\n",
    "ovr_probs_ = ovr_lgr.predict_proba(X_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(ovr_probs, ovr_probs_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-484717eb2739b6b5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Trying multinomial\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, fit a `LogisticRegression` estimator with `multi_class = 'multinomial'` and `random_state = 42`.  Fit the model on the training data as `multi_lgr` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27b62c19a3e13379",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "multi_lgr = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "multi_lgr = LogisticRegression(multi_class='multinomial', random_state=42).fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "multi_lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-45fce274c74b772e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "multi_lgr_ = LogisticRegression(multi_class='multinomial', random_state=42).fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert multi_lgr.multi_class == multi_lgr_.multi_class\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1cd6899727717623",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Examining the Probabilities\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Again, examine the probabilities from the multinomial estimator above on the test data.  Assign them as an array to `multi_probs` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76ecf062d62d7ac5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "multi_probs = multi_lgr.predict_proba(X_test)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "multi_probs = multi_lgr.predict_proba(X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "pd.DataFrame(multi_probs, columns = ['p(adelie)', 'p(gentoo)', 'p(chinstrap)']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ae793e4ee0268e49",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "multi_lgr_ = LogisticRegression(multi_class='multinomial', random_state=42).fit(X_train, y_train)\n",
    "multi_probs_ = multi_lgr.predict_proba(X_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(multi_probs, multi_probs_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-829714790aa8038d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### One vs. One Classifier\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Similar in thinking to the one vs. rest approach, the one vs. one approach pairs every combination of the target class and builds a logistic model on this binary problem.  This means that for three classes you would have 6 different logistic regressors.  \n",
    "\n",
    "The LogisticRegression estimator does not have this as a default but scikitlearn implements this approach through the `OneVsOneClassifier` that accepts a classification estimator. Below, instantiate a `OneVsOneClassifier` with a `LogisticRegression` estimator os `ovo_clf` below, and fit this on the training data. In your Logistic estimator set `random_state = 42`.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7f080ac18ecc63d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ovo_clf = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ovo_clf = OneVsOneClassifier(LogisticRegression(random_state = 42)).fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "ovo_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-241d47c6d7482459",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ovo_clf_ = OneVsOneClassifier(LogisticRegression(random_state = 42)).fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(ovo_clf) == type(ovo_clf_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d8c60d80a8f7139",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Comparing Performance\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Create a DataFrame that contains the scores on testing data in terms of accuracy.  Assign to `eval_df` below.  Which classifier performed best in terms of accuracy?  Assign your answer as a string -- `ovr`, `multi`, or `ovo` -- below to `best_acc`. \n",
    "\n",
    "| estimator | accuracy | \n",
    "| ------ | ------ |\n",
    "| ovo | - |\n",
    "| multi | - |\n",
    "| ovo | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21c1289df7ce1c76",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "best_acc = ''\n",
    "### BEGIN SOLUTION\n",
    "best_acc = 'multi'\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c04046b81fdc2cad",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_acc_ = 'multi'\n",
    "#\n",
    "#\n",
    "#\n",
    "assert best_acc == best_acc_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6c7b9795de3ecce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Hopefully this activity increased your facility with the `LogisticRegression` estimator and how it can be used in a multi-class setting.  Of course, these options are things you may consider in a grid search rather than fitting each on their own, however the One vs. One will have to implemented as its own object.  Further, many of the fitting procedures should raise warnings.  As seen before, there is regularization behind the scenes so scaling the data should happen prior to fitting.  Further, you may need to give the estimator more time for the gradient descent to converge, which you can control with the `max_iter` argument."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
