{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-434c12606c8da4d4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 13.6: Use L1 Regularization to Select Features\n",
    "\n",
    "**Expected Time = 90 minutes** \n",
    "\n",
    "**Total Points = 60** \n",
    "\n",
    "This activity focuses on using the L1 regularization penalty to select features in a classification setting.  In the following, you will explore the value of different coefficients as you increase regularization.  Be sure to use the `liblinear` solver in your models throughout.\n",
    "\n",
    "### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02346417d82c244c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "For this exercise you will use the built in dataset from seaborn containing information on passengers on the titanic.  Here, you will only use the numeric features.  The data is loaded and prepared below.  We will only use one set for `X` and `y` to explore the effect of added regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset('titanic').dropna()\n",
    "# data = data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.select_dtypes(np.number).drop('survived', axis = 1), data.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14e8c4ba88a8ff6b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Scaling the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Because we are using regularization, it is important to have each of the features represented on the same scale.  To do so, use the `StandardScaler` to create `X_scaled` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe85fbba36fdc52e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "scaler = ''\n",
    "X_scaled = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "X_scaled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8be93cbe9e710825",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "scaler = StandardScaler()\n",
    "X_scaled_ = scaler.fit_transform(X)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(X_scaled, X_scaled_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc85d4a58e07b2df",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### `C` values to explore\n",
    "\n",
    "**20 Points**\n",
    "\n",
    "Next, you want to create an array of different `C` values to explore.  Remember that `C` is actually the inverse of regularization so small values are large amounts of regularization.  \n",
    "\n",
    "\n",
    "Use the array of `Cs` below to create models on `X_scaled` and `y`.  Keep track of the coefficients (as a list not array!) in a list `coef_list` below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aae58f02ef963a34",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "coef_list = []\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "coef_list = []\n",
    "for C in Cs:\n",
    "    lgr = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = C, random_state=42, max_iter = 1000).fit(X_scaled, y)\n",
    "    coef_list.append(list(lgr.coef_[0]))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "coef_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-15dfeed25481089c",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "coef_list_ = []\n",
    "for C in Cs:\n",
    "    lgr_ = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = C, random_state=42, max_iter = 1000).fit(X_scaled, y)\n",
    "    coef_list_.append(list(lgr_.coef_[0]))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert coef_list == coef_list_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-514e23e2952ef188",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### DataFrame of Coefficients\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Next, create a DataFrame based on the coefficients in `coef_list`.  Set the index of this DataFrame to the `Cs` values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9f093659e90947d2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "coef_df = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "coef_df = pd.DataFrame(coef_list, columns = X.columns)\n",
    "coef_df.index = Cs\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-153ee1cbf9c8502e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "coef_list_ = []\n",
    "for C in Cs:\n",
    "    lgr_ = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = C, random_state=42, max_iter = 1000).fit(X_scaled, y)\n",
    "    coef_list_.append(list(lgr_.coef_[0]))\n",
    "coef_df_ = pd.DataFrame(coef_list_, columns = X.columns)\n",
    "coef_df_.index = Cs\n",
    "#\n",
    "#\n",
    "#\n",
    "pd.testing.assert_frame_equal(coef_df, coef_df_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8413bfa5cef56c93",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Visualizing the Results\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, the data from the coefficients is plotted.  Based on this plot, which feature seems more important -- `age` or `parch`?  Assign your answer as a string to `ans4` below.\n",
    "\n",
    "<center>\n",
    "    <img src = 'images/coefl1.png' />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (12, 5))\n",
    "# plt.semilogx(coef_df)\n",
    "# plt.gca().invert_xaxis()\n",
    "# plt.grid()\n",
    "# plt.legend(list(coef_df.columns));\n",
    "# plt.title('Increasing Regularization on Titanic Features')\n",
    "# plt.xlabel(\"Increasing 1/C\")\n",
    "# plt.savefig('images/coefl1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd54918ce21614da",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ans4 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans4 = 'age'\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-139da347a80f80fb",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans4_ = 'age'\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans4 == ans4_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4dd86964040b7e2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Using `SelectFromModel`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In a similar manner, you can use `SelectFromModel` together with `LogisticRegression` to select features based on coefficient values.  Below, create an instance of the `SelectFromModel` selector with a `LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', random_state = 43)` as the estimator.  Fit and transform the data to select the 3 most important features.  Assign their names as a list to `three_best` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45c9ea94609d65d8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "selector = ''\n",
    "best_features = ''\n",
    "### BEGIN SOLUTION\n",
    "selector = SelectFromModel(LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear', random_state = 43))\n",
    "ans = selector.fit_transform(X_scaled, y)\n",
    "best_features = ['age', 'fare']\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(selector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-09ba1d382079306e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_features_ = ['age', 'fare']\n",
    "#\n",
    "#\n",
    "#\n",
    "assert set(best_features) == set(best_features_)\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
