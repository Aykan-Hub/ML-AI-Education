{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost\n",
    "\n",
    "This activity focuses on using the `AdaBoostClassifier` and the performance resulting from changing the base classifier that is used.  As discussed in the lectures, adaptive boosting is a successive reweighting of data using a set number of estimators.  These weighted estimators are what form the ensemble, and the predictions are a result of a weighted combination of the estimators.  \n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fetal.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fetal_health', axis = 1).values\n",
    "y = df['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### `AdaBoostClassifier`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "What is the default estimator in the `AdaBoostClassifier`?  Instantiate this with the correct hyperparameters to `ans1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "ans1 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans1 = DecisionTreeClassifier(max_depth=1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans1_ = DecisionTreeClassifier(max_depth=1)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans1.max_depth == ans1_.max_depth\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Fitting the Ensemble\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `AdaBoostClassifier` to fit the data.  Use all default settings and and assign the accuracy of the model on the test data to `model_1_acc` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881578947368421\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "model_1 = ''\n",
    "model_1_acc = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model_1 = AdaBoostClassifier().fit(X_train, y_train)\n",
    "model_1_acc = model_1.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model_1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "model_1_ = AdaBoostClassifier().fit(X_train, y_train)\n",
    "model_1_acc_ = model_1_.score(X_test, y_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert model_1_acc_ == model_1_acc\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Grid Searching the Ensemble\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "As the documentation states [here](https://scikit-learn.org/stable/modules/ensemble.html#usage), the main parameters to search are the number of estimators and the complexity of the base estimator.  Create a parameter grid that considers the following parameters:\n",
    "\n",
    "- *number of estimators*: 100, 200\n",
    "- *max_depths*: 1, 2, 3\n",
    "\n",
    "as `params` below.  Use this with the `AdaBoostClassifier` to grid search named `tree_grid` on the train data.  Assign the score on the test data as `grid_acc`.\n",
    "\n",
    "This estimator will likely time out the grader.  To avoid this, you will save the results of the model to a file using the `joblib` library.  After fitting your estimator, assign this to a file named `grid_model.joblib` **and place this file in the `models` folder**.  The grader will load this model and compare it to the expected score on the test data.  Look over the documentation of `joblib` [here](https://scikit-learn.org/stable/model_persistence.html#python-specific-serialization).  Assign the score of the model on the test data by loading the `.joblib` model and scoring it using the test data as `score` below.\n",
    "\n",
    "> *Model persistance is an important idea.  Consider looking over the more general `pickle` library for serialization as well.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soln_1.joblib']\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "model_files = os.listdir('models')\n",
    "score = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "model_files = os.listdir('models')\n",
    "s = load('models/soln_1.joblib')\n",
    "score = s.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "a = load('models/soln_1.joblib')\n",
    "ans = a.score(X_test, y_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans == score\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### A Different Base Estimator\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consider using a different base estimator such as `LogisticRegression` estimator.  Explore the neighbors parameters with \n",
    "\n",
    "- `C = [.001, 0.01, 0.1, 1.0, 10.0]`\n",
    "\n",
    "Create a `Pipeline` that scales the data first and then implements an `AdaBoostClassifier` with `random_state = 42` and a Logistic Regression model.  Grid search the pipeline with a grid   again writing the model out to a file named `lgr.joblib` in the `models` folder.  Assign the score on the test data to `score2`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "score2 = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "s = load('models/ans2.joblib')\n",
    "score2 = s.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "# params_ = {'mod__base_estimator__C': [.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "# p = Pipeline([('scale', StandardScaler()),\n",
    "#              ('mod', AdaBoostClassifier(base_estimator = LogisticRegression(), \n",
    "#                                        random_state = 42))\n",
    "#              ])\n",
    "# g = GridSearchCV(p,\n",
    "#                 param_grid=params_)\n",
    "# g.fit(X_train, y_train)\n",
    "a = load('models/ans2.joblib')\n",
    "#\n",
    "#\n",
    "#\n",
    "assert a.score(X_test, y_test) == score2\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Evaluating the models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Which model performed the best on the test data?\n",
    "\n",
    "- `a`: Base `AdaBoostClassifier`\n",
    "- `b`: Grid Searched Tree Model\n",
    "- `c`: Grid Searched Logistic Model\n",
    "- `d`: None of the above\n",
    "\n",
    "Assign your answer as a string to `ans5` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans5 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans5 = 'b'\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans5_ = 'b'\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans5 == ans5_\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
